"""
Reklamshik API - FastAPI backend –¥–ª—è Mini App.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π scanner –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–æ–≤.
"""

import os
import sys
import json
import re
import hmac
import hashlib
import asyncio
import time
from pathlib import Path
from datetime import datetime
from io import BytesIO
from urllib.parse import parse_qs

# v48.1: Regex –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Telegram username
USERNAME_REGEX = re.compile(r'^[a-zA-Z][a-zA-Z0-9_]{4,31}$')
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
from dotenv import load_dotenv
import httpx

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ scanner (–Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: /root/reklamshik/)
backend_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(backend_dir)  # mini-app -> project root
sys.path.insert(0, backend_dir)
sys.path.insert(0, project_root)

# v58.0: –ò–º–ø–æ—Ä—Ç –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –¥–ª—è breakdown
try:
    from scanner.json_compression import decompress_breakdown
except ImportError:
    # Fallback –µ—Å–ª–∏ scanner –Ω–µ –Ω–∞–π–¥–µ–Ω (legacy)
    decompress_breakdown = lambda x: x

load_dotenv()


# ============================================================================
# v62.0: Analytics - Telegram initData verification
# ============================================================================

def verify_telegram_init_data(init_data: str, bot_token: str) -> dict | None:
    """
    –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç initData –æ—Ç Telegram –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç user_id.
    –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –í–°–ï–• –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–Ω–µ —Ç–æ–ª—å–∫–æ Premium).
    """
    if not init_data or not bot_token:
        return None
    try:
        parsed = parse_qs(init_data)
        received_hash = parsed.get('hash', [''])[0]
        if not received_hash:
            return None

        # –°–æ–∑–¥–∞—ë–º data-check-string
        data_check_parts = []
        for key in sorted(parsed.keys()):
            if key != 'hash':
                data_check_parts.append(f"{key}={parsed[key][0]}")
        data_check_string = '\n'.join(data_check_parts)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–ø–∏—Å—å
        secret_key = hmac.new(b"WebAppData", bot_token.encode(), hashlib.sha256).digest()
        calculated_hash = hmac.new(secret_key, data_check_string.encode(), hashlib.sha256).hexdigest()

        if calculated_hash != received_hash:
            return None

        # –ò–∑–≤–ª–µ–∫–∞–µ–º user
        user_str = parsed.get('user', [''])[0]
        if user_str:
            user = json.loads(user_str)
            return {'user_id': user.get('id'), 'username': user.get('username')}
        return None
    except Exception:
        return None


def get_user_id_from_request(request) -> int | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç user_id –∏–∑ X-Telegram-Init-Data header."""
    init_data = request.headers.get('X-Telegram-Init-Data')
    if not init_data:
        return None
    bot_token = os.getenv("BOT_TOKEN")
    user_data = verify_telegram_init_data(init_data, bot_token)
    return user_data.get('user_id') if user_data else None


# v15.0: CPM-based —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (—Ä—É–±–ª–µ–π –∑–∞ 1000 –ü–†–û–°–ú–û–¢–†–û–í)
# –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–∞–ª—å–Ω—ã–º —Å–¥–µ–ª–∫–∞–º:
# - –ö—Ä–∏–ø—Ç–æ 800 views, score 82 = $30 = 2700‚ÇΩ
# - TECH 2900 views, score 80 = ~$32 = 2900‚ÇΩ
# - AI_ML 2900 views, score 80 = ~$27 = 2465‚ÇΩ
CPM_RATES = {
    # –ü—Ä–µ–º–∏—É–º (–∫—Ä–∏–ø—Ç–æ —Å–∞–º–∞—è –¥–æ—Ä–æ–≥–∞—è!)
    "CRYPTO":       {"low": 800,  "avg": 1500, "high": 3000},
    "FINANCE":      {"low": 650,  "avg": 1000, "high": 1700},
    "REAL_ESTATE":  {"low": 500,  "avg": 850,  "high": 1500},
    "BUSINESS":     {"low": 400,  "avg": 650,  "high": 1200},

    # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ (~3x –¥–µ—à–µ–≤–ª–µ –∫—Ä–∏–ø—Ç—ã)
    "TECH":         {"low": 350,  "avg": 600,  "high": 1000},
    "AI_ML":        {"low": 300,  "avg": 500,  "high": 850},

    # –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ/–õ–∞–π—Ñ—Å—Ç–∞–π–ª
    "EDUCATION":    {"low": 200,  "avg": 350,  "high": 600},
    "BEAUTY":       {"low": 130,  "avg": 230,  "high": 400},
    "HEALTH":       {"low": 130,  "avg": 230,  "high": 400},
    "TRAVEL":       {"low": 170,  "avg": 300,  "high": 500},

    # –ö–æ–Ω—Ç–µ–Ω—Ç (—Å–∞–º—ã–µ –¥–µ—à—ë–≤—ã–µ)
    "RETAIL":       {"low": 85,   "avg": 150,  "high": 300},
    "NEWS":         {"low": 65,   "avg": 170,  "high": 400},
    "ENTERTAINMENT":{"low": 35,   "avg": 85,   "high": 170},
    "LIFESTYLE":    {"low": 100,  "avg": 200,  "high": 400},

    # –†–∏—Å–∫ (–≤—ã—Å–æ–∫–∏–π CPM –Ω–æ —Å–ª–æ–∂–Ω–æ –ø—Ä–æ–¥–∞—Ç—å)
    "GAMBLING":     {"low": 650,  "avg": 1150, "high": 1700},
    "ADULT":        {"low": 65,   "avg": 130,  "high": 200},
    "OTHER":        {"low": 65,   "avg": 130,  "high": 270},
}

# v15.0: –ö–æ—Ä–∏–¥–æ—Ä —Ü–µ–Ω ¬±10% –æ—Ç —Ä–∞—Å—á—ë—Ç–Ω–æ–π —Ü–µ–Ω—ã
PRICE_RANGE = 0.10


def normalize_category(category: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é: uppercase + fallback –Ω–∞ OTHER."""
    if not category:
        return "OTHER"
    cat = category.upper().replace("/", "_").replace(" ", "_")
    if cat not in CPM_RATES:
        return "OTHER"
    return cat


def get_cpm_by_score(category: str, score: int, trust_factor: float = 1.0) -> int:
    """
    v15.0: –í—ã–±–∏—Ä–∞–µ—Ç CPM –ø–æ score (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å).
    Score 80 vs 60 = —Ä–∞–∑–Ω–∏—Ü–∞ –≤ 2-3 —Ä–∞–∑–∞!
    """
    category = normalize_category(category)
    rates = CPM_RATES[category]
    effective_score = score * trust_factor

    if effective_score >= 80:
        return rates["high"]
    elif effective_score >= 70:
        # 70-80: –±–ª–∏–∑–∫–æ –∫ high
        ratio = (effective_score - 70) / 10
        return int(rates["avg"] + (rates["high"] - rates["avg"]) * (0.5 + ratio * 0.5))
    elif effective_score >= 55:
        # 55-70: avg –∑–æ–Ω–∞
        ratio = (effective_score - 55) / 15
        return int(rates["avg"] * (0.8 + ratio * 0.2))
    elif effective_score >= 40:
        # 40-55: low-avg
        ratio = (effective_score - 40) / 15
        return int(rates["low"] + (rates["avg"] - rates["low"]) * ratio * 0.5)
    else:
        # <40: –Ω–∏–∂–µ low
        return int(rates["low"] * max(0.3, effective_score / 40))


# Pydantic models
class Recommendation(BaseModel):
    type: str  # cpm, tip, warning, success
    icon: str  # emoji
    text: str


class ChannelSummary(BaseModel):
    username: str
    title: Optional[str] = None  # v58.2: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
    score: int
    verdict: str
    trust_factor: float
    members: int
    category: Optional[str] = None
    category_secondary: Optional[str] = None
    category_percent: Optional[int] = None  # v20.0: –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    scanned_at: Optional[str] = None
    cpm_min: Optional[int] = None
    cpm_max: Optional[int] = None
    photo_url: Optional[str] = None  # v19.0: –∞–≤–∞—Ç–∞—Ä–∫–∞ –∫–∞–Ω–∞–ª–∞
    is_verified: bool = False  # v34.0: Telegram –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è


class ChannelListResponse(BaseModel):
    channels: List[ChannelSummary]
    total: int
    page: int
    page_size: int
    has_more: bool


class StatsResponse(BaseModel):
    total: int
    good: int
    bad: int
    waiting: int
    error: int


class CategoryStat(BaseModel):
    category: str
    count: int
    cpm_min: int
    cpm_max: int


class CategoryStatsResponse(BaseModel):
    categories: List[CategoryStat]
    total_categorized: int
    uncategorized: int


# v49.0: Live Scan models
class ScanRequest(BaseModel):
    username: str


class ScanResponse(BaseModel):
    success: bool
    channel: Optional[dict] = None
    error: Optional[str] = None


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
db = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """–ó–∞–ø—É—Å–∫ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    global db

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º scanner –º–æ–¥—É–ª–∏
    from scanner.database import CrawlerDB

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    db_path = os.getenv("DATABASE_PATH", "crawler.db")
    db = CrawlerDB(db_path)
    print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {db_path}")

    # v62.0: Analytics table
    db.conn.execute("PRAGMA journal_mode=WAL")
    db.conn.execute("""
        CREATE TABLE IF NOT EXISTS analytics_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            event_type TEXT NOT NULL,
            user_id INTEGER DEFAULT NULL,
            session_id TEXT DEFAULT NULL,
            username TEXT DEFAULT NULL,
            score INTEGER DEFAULT NULL,
            verdict TEXT DEFAULT NULL,
            duration_ms INTEGER DEFAULT NULL,
            status TEXT DEFAULT NULL,
            error_message TEXT DEFAULT NULL,
            properties TEXT DEFAULT NULL,
            platform TEXT DEFAULT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    db.conn.execute("CREATE INDEX IF NOT EXISTS idx_analytics_created ON analytics_events(created_at DESC)")
    db.conn.execute("CREATE INDEX IF NOT EXISTS idx_analytics_type ON analytics_events(event_type)")
    db.conn.execute("CREATE INDEX IF NOT EXISTS idx_analytics_user ON analytics_events(user_id)")
    db.conn.commit()
    print("v62.0: Analytics table ready")

    yield

    # Cleanup
    if db:
        db.close()
    print("–°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


app = FastAPI(
    title="Reklamshik API",
    description="API –¥–ª—è Telegram Mini App –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–æ–≤",
    version="1.0.0",
    lifespan=lifespan
)


# ============================================================================
# v62.0: Analytics - Async logging helper
# ============================================================================

async def log_analytics(
    event_type: str,
    user_id: int = None,
    username: str = None,
    score: int = None,
    verdict: str = None,
    duration_ms: int = None,
    status: str = "success",
    error_message: str = None,
    properties: dict = None,
    platform: str = None
):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ª–æ–≥–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ª–æ–º–∞–µ—Ç endpoint –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    try:
        props_json = json.dumps(properties, ensure_ascii=False) if properties else None
        await asyncio.to_thread(
            _sync_log_event,
            event_type, user_id, username, score, verdict,
            duration_ms, status, error_message, props_json, platform
        )
    except Exception:
        pass  # Silent fail


def _sync_log_event(event_type, user_id, username, score, verdict,
                    duration_ms, status, error_message, props_json, platform):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ SQLite."""
    if db is None:
        return
    cursor = db.conn.cursor()
    cursor.execute("""
        INSERT INTO analytics_events
        (event_type, user_id, username, score, verdict, duration_ms, status, error_message, properties, platform)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (event_type, user_id, username, score, verdict, duration_ms, status, error_message, props_json, platform))
    db.conn.commit()


# CORS –¥–ª—è Mini App
# –†–∞–∑—Ä–µ—à–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã + Telegram WebView
ALLOWED_ORIGINS = [
    "https://ads.factchain-traker.online",  # Production frontend
    "http://localhost:5173",                 # Vite dev server
    "http://localhost:3000",                 # Alternative dev
    "https://web.telegram.org",              # Telegram Web
    "https://weba.telegram.org",             # Telegram Web A
    "https://webk.telegram.org",             # Telegram Web K
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=False,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)


def estimate_avg_views(members: int, breakdown: dict = None, score: int = 50) -> int:
    """
    v15.0: –û—Ü–µ–Ω–∫–∞ —Å—Ä–µ–¥–Ω–∏—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ—Å—Ç–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç reach% –∏–∑ breakdown –∏–ª–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–æ score.
    """
    if members <= 0:
        return 100  # –ú–∏–Ω–∏–º—É–º

    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å reach –∏–∑ breakdown
    reach_percent = 10.0  # Default 10%

    if breakdown:
        quality = breakdown.get('quality', {})
        items = quality.get('items', {})
        reach_item = items.get('reach', {})
        # reach value –æ–±—ã—á–Ω–æ 0-20 (–ø—Ä–æ—Ü–µ–Ω—Ç) - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —á–∏—Å–ª–æ–º
        if 'value' in reach_item:
            try:
                val = reach_item['value']
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å % - —É–±–∏—Ä–∞–µ–º %
                if isinstance(val, str):
                    val = val.replace('%', '').strip()
                reach_percent = max(1, min(50, float(val)))
            except (ValueError, TypeError):
                pass  # –ò—Å–ø–æ–ª—å–∑—É–µ–º default
        elif reach_item.get('score', 0) > 0:
            # –û—Ü–µ–Ω–∫–∞ –ø–æ score: score 10/10 = 20% reach
            reach_percent = (reach_item['score'] / reach_item.get('max', 10)) * 20

    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ score (—Ö–æ—Ä–æ—à–∏–π –∫–∞–Ω–∞–ª = –ª—É—á—à–∏–π reach)
    score_factor = 0.7 + (score / 100) * 0.6  # 0.7 - 1.3

    avg_views = int(members * (reach_percent / 100) * score_factor)
    return max(100, avg_views)  # –ú–∏–Ω–∏–º—É–º 100 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤


def calculate_post_price(
    category: Optional[str],
    members: int,
    trust_factor: float = 1.0,
    score: int = 50,
    breakdown: dict = None,
    trust_penalties: list = None,
    avg_views: int = None  # v59.6: –†–µ–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ë–î
) -> tuple:
    """
    v15.0: CPM-based —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.

    –§–æ—Ä–º—É–ª–∞:
        price = (avg_views / 1000) √ó CPM
        CPM –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ score (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ)

    Returns:
        (price_min, price_max): –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω –∑–∞ –ø–æ—Å—Ç –≤ —Ä—É–±–ª—è—Ö (¬±10%)
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–ù–ò–ö–û–ì–î–ê –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None!)
    category = normalize_category(category)

    # v59.6: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ avg_views –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—Ü–µ–Ω–∏–≤–∞–µ–º
    if avg_views is None or avg_views <= 0:
        avg_views = estimate_avg_views(members, breakdown, score)

    # –ü–æ–ª—É—á–∞–µ–º CPM –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ score
    cpm = get_cpm_by_score(category, score, trust_factor)

    # v15.0: –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞ CPM
    price_center = int((avg_views / 1000) * cpm)

    # –ö–æ—Ä–∏–¥–æ—Ä ¬±10%
    price_min = max(100, int(price_center * (1 - PRICE_RANGE)))
    price_max = max(200, int(price_center * (1 + PRICE_RANGE)))

    return price_min, price_max


def calculate_post_price_details(
    category: Optional[str],
    members: int,
    trust_factor: float = 1.0,
    score: int = 50,
    breakdown: dict = None,
    trust_penalties: list = None,
    avg_views: int = None  # v59.6: –†–µ–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ë–î
) -> dict:
    """
    v15.0: CPM-based —Ä–∞—Å—á—ë—Ç —Å –¥–µ—Ç–∞–ª—è–º–∏ –¥–ª—è UI.
    –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict (–Ω–∏–∫–æ–≥–¥–∞ None).
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    category = normalize_category(category)
    rates = CPM_RATES[category]

    # v59.6: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ avg_views –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—Ü–µ–Ω–∏–≤–∞–µ–º
    if avg_views is None or avg_views <= 0:
        avg_views = estimate_avg_views(members, breakdown, score)

    # –ü–æ–ª—É—á–∞–µ–º CPM –ø–æ score
    cpm = get_cpm_by_score(category, score, trust_factor)

    # v15.0: –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞
    price_center = int((avg_views / 1000) * cpm)
    price_min = max(100, int(price_center * (1 - PRICE_RANGE)))
    price_max = max(200, int(price_center * (1 + PRICE_RANGE)))

    return {
        "min": price_min,
        "max": price_max,
        "cpm": cpm,
        "cpm_low": rates["low"],
        "cpm_high": rates["high"],
        "avg_views": avg_views,
        "category": category,
        "score": score,
        "trust_factor": round(trust_factor, 2),
    }


def get_cpm_range(category: Optional[str]) -> tuple:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç CPM –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
    category = normalize_category(category)
    rates = CPM_RATES[category]
    return rates["low"], rates["high"]


def estimate_breakdown(score: int, trust_factor: float = 1.0) -> dict:
    """
    v65.0: –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π breakdown –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ score.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback –∫–æ–≥–¥–∞ –Ω–µ—Ç breakdown_json –≤ –ë–î.
    –í–µ—Å–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å RAW_WEIGHTS –≤ scanner/scorer.py (v48.0).

    - Quality (42 max): forward_rate(15), cv_views(12), reach(8), regularity(7)
    - Engagement (38 max): comments(15), er_trend(10), reaction_rate(8), reaction_stability(5)
    - Reputation (20 max): age(7), premium(7), source_diversity(6)
    """
    # Raw score –¥–æ trust factor
    raw_score = score / trust_factor if trust_factor > 0 else score
    raw_score = min(100, raw_score)

    # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
    pct = raw_score / 100

    # v55.0: –í–µ—Å–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å RAW_WEIGHTS –≤ scorer.py (v48.0)
    weights = {
        'quality': {
            'forward_rate': {'max': 15, 'label': '–†–µ–ø–æ—Å—Ç—ã'},      # v48.0: +8 (–≤–∏—Ä–∞–ª—å–Ω–æ—Å—Ç—å)
            'cv_views': {'max': 12, 'label': 'CV –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤'},    # v48.0: -3
            'reach': {'max': 8, 'label': '–û—Ö–≤–∞—Ç'},                # v48.0: -2
            'regularity': {'max': 7, 'label': '–†–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å'},    # v48.0: NEW
            # views_decay —É–±—Ä–∞–Ω –≤ v48.0 ‚Üí –æ—Å—Ç–∞–ª—Å—è –≤ Trust Factor
        },
        'engagement': {
            'comments': {'max': 15, 'label': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏'},
            'er_trend': {'max': 10, 'label': '–¢—Ä–µ–Ω–¥ ER'},
            'reaction_rate': {'max': 8, 'label': '–†–µ–∞–∫—Ü–∏–∏'},      # v48.0: -7 (–ª–µ–≥–∫–æ –Ω–∞–∫—Ä—É—Ç–∏—Ç—å)
            'reaction_stability': {'max': 5, 'label': '–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å ER'},  # v65.0: fix key
        },
        'reputation': {
            'age': {'max': 7, 'label': '–í–æ–∑—Ä–∞—Å—Ç'},
            'premium': {'max': 7, 'label': '–ü—Ä–µ–º–∏—É–º—ã'},
            'source_diversity': {'max': 6, 'label': '–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å'},  # v65.0: fix key
        },
    }

    breakdown = {}

    for category, items in weights.items():
        cat_max = sum(item['max'] for item in items.values())
        cat_score = int(cat_max * pct)

        breakdown[category] = {
            'total': cat_score,
            'max': cat_max,
            'items': {}
        }

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–ª–ª—ã –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤–µ—Å–∞–º
        remaining = cat_score
        item_list = list(items.items())

        for i, (key, item) in enumerate(item_list):
            if i == len(item_list) - 1:
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ–ª—É—á–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫
                item_score = remaining
            else:
                # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤–µ—Å—É
                item_score = int(item['max'] * pct)
                remaining -= item_score

            breakdown[category]['items'][key] = {
                'score': min(item_score, item['max']),
                'max': item['max'],
                'label': item['label']
            }

    return breakdown


def format_llm_analysis_for_ui(llm_data: dict) -> dict:
    """
    v41.0: –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç LLM –∞–Ω–∞–ª–∏–∑ –¥–ª—è UI.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:

    1. –ü–ª–æ—Å–∫–∞—è (v41.0 crawler):
    {
        'ad_percentage': 15,
        'bot_percentage': 8,
        'trust_score': 65,
        'llm_trust_factor': 0.85,
        'ad_mult': 1.0,
        'bot_mult': 1.0
    }

    v41.0: authenticity –£–î–ê–õ–ï–ù–ê (–¥—É–±–ª–∏–∫–∞—Ç bot_percentage).

    2. –í–ª–æ–∂–µ–Ω–Ω–∞—è (—Å—Ç–∞—Ä–∞—è):
    {
        'tier': 'STANDARD',
        'posts': {...},
        'comments': {...}
    }
    """
    if not llm_data:
        return None

    result = {
        'tier': llm_data.get('tier', 'STANDARD'),
        'tier_cap': llm_data.get('tier_cap', 100),
        'exclusion_reason': llm_data.get('exclusion_reason'),
        'llm_bonus': round(llm_data.get('llm_bonus', 0), 1),
        'llm_trust_factor': round(llm_data.get('llm_trust_factor', 1.0), 2),
    }

    # v41.0: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–æ—Ç –Ω–æ–≤–æ–≥–æ crawler)
    has_flat_data = 'ad_percentage' in llm_data or 'bot_percentage' in llm_data

    if has_flat_data:
        # –ü–ª–æ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Äî —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ posts/comments
        ad_pct = llm_data.get('ad_percentage')
        if ad_pct is not None:
            result['posts'] = {
                'ad_percentage': {
                    'value': ad_pct,
                    'label': '–†–µ–∫–ª–∞–º—ã %',
                    'status': _get_metric_status(ad_pct, good_max=20, warning_max=40)
                }
            }

        # v41.0: authenticity REMOVED
        bot_pct = llm_data.get('bot_percentage')
        trust = llm_data.get('trust_score')

        if bot_pct is not None or trust is not None:
            result['comments'] = {}
            if bot_pct is not None:
                result['comments']['bot_percentage'] = {
                    'value': bot_pct,
                    'label': '–ë–æ—Ç–æ–≤ %',
                    'status': _get_metric_status(bot_pct, good_max=20, warning_max=50)
                }
            if trust is not None:
                result['comments']['trust_score'] = {
                    'value': trust,
                    'label': '–î–æ–≤–µ—Ä–∏–µ',
                    'status': _get_reverse_status(trust, good_min=60, warning_min=30)
                }

        return result

    # –°—Ç–∞—Ä–∞—è –≤–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
    posts = llm_data.get('posts')
    if posts:
        result['posts'] = {
            'brand_safety': {
                'value': posts.get('brand_safety', 0),
                'label': 'Brand Safety',
                'status': _get_brand_safety_status(posts.get('brand_safety', 0))
            },
            'toxicity': {
                'value': posts.get('toxicity', 0),
                'label': '–¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å',
                'status': _get_metric_status(posts.get('toxicity', 0), good_max=10, warning_max=40)
            },
            'violence': {
                'value': posts.get('violence', 0),
                'label': '–ù–∞—Å–∏–ª–∏–µ',
                'status': _get_metric_status(posts.get('violence', 0), good_max=10, warning_max=30)
            },
            'political_quantity': {
                'value': posts.get('political_quantity', 0),
                'label': '–ü–æ–ª–∏—Ç–∏–∫–∞ %',
                'status': _get_metric_status(posts.get('political_quantity', 0), good_max=15, warning_max=40)
            },
            'political_risk': {
                'value': posts.get('political_risk', 0),
                'label': '–ü–æ–ª–∏—Ç. —Ä–∏—Å–∫',
                'status': _get_metric_status(posts.get('political_risk', 0), good_max=20, warning_max=50)
            },
            'misinformation': {
                'value': posts.get('misinformation', 0),
                'label': '–î–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è',
                'status': _get_metric_status(posts.get('misinformation', 0), good_max=10, warning_max=30)
            },
            'ad_percentage': {
                'value': posts.get('ad_percentage', 0),
                'label': '–†–µ–∫–ª–∞–º—ã %',
                'status': _get_metric_status(posts.get('ad_percentage', 0), good_max=20, warning_max=40)
            },
            'red_flags': posts.get('red_flags', [])
        }

    comments = llm_data.get('comments')
    if comments:
        # v41.0: authenticity REMOVED
        result['comments'] = {
            'bot_percentage': {
                'value': comments.get('bot_percentage', 0),
                'label': '–ë–æ—Ç–æ–≤ %',
                'status': _get_metric_status(comments.get('bot_percentage', 0), good_max=20, warning_max=50)
            },
            'bot_signals': comments.get('bot_signals', []),
            'trust_score': {
                'value': comments.get('trust_score', 0),
                'label': '–î–æ–≤–µ—Ä–∏–µ',
                'status': _get_reverse_status(comments.get('trust_score', 0), good_min=60, warning_min=30)
            },
            'trust_signals': comments.get('trust_signals', [])
        }

    return result


def _get_brand_safety_status(value: int) -> str:
    """–°—Ç–∞—Ç—É—Å –¥–ª—è brand_safety (—á–µ–º –≤—ã—à–µ - —Ç–µ–º –ª—É—á—à–µ)."""
    if value >= 80:
        return 'good'
    elif value >= 60:
        return 'warning'
    return 'bad'


def _get_metric_status(value: int, good_max: int, warning_max: int) -> str:
    """–°—Ç–∞—Ç—É—Å –¥–ª—è –º–µ—Ç—Ä–∏–∫ –≥–¥–µ –Ω–∏–∑–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = —Ö–æ—Ä–æ—à–æ (toxicity, violence, etc)."""
    if value <= good_max:
        return 'good'
    elif value <= warning_max:
        return 'warning'
    return 'bad'


def _get_reverse_status(value: int, good_min: int, warning_min: int) -> str:
    """–°—Ç–∞—Ç—É—Å –¥–ª—è –º–µ—Ç—Ä–∏–∫ –≥–¥–µ –≤—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = —Ö–æ—Ä–æ—à–æ (trust)."""
    if value >= good_min:
        return 'good'
    elif value >= warning_min:
        return 'warning'
    return 'bad'


def format_breakdown_for_ui(breakdown_data: dict, llm_analysis: dict = None) -> dict:
    """
    v23.0: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π breakdown –∏–∑ scorer.py –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è UI.
    v39.0: –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç LLM –¥–∞–Ω–Ω—ã–µ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ).

    scorer.py –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        {
            'breakdown': {
                'cv_views': {'value': 45.2, 'points': 12, 'max': 13},
                'reach': {'value': 8.5, 'points': 8, 'max': 10},
                'ad_load': {'value': 15.0, 'status': 'normal'},  # INFO METRIC
                'posting_frequency': {'posts_per_day': 2.5, 'status': 'normal'},  # INFO METRIC
                ...
            },
            'categories': {
                'quality': {'score': 30, 'max': 40},
                'engagement': {'score': 33, 'max': 40},
                'reputation': {'score': 15, 'max': 20}
            }
        }

    UI –æ–∂–∏–¥–∞–µ—Ç:
        {
            'quality': {
                'total': 30, 'max': 40,
                'items': {
                    'cv_views': {'score': 12, 'max': 13, 'label': 'CV –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤'},
                    ...
                },
                'info_metrics': {
                    'ad_load': {'value': '15%', 'label': '–†–µ–∫–ª. –Ω–∞–≥—Ä—É–∑–∫–∞', 'status': 'good'},
                    ...
                }
            },
            ...
        }

    v39.0: –ï—Å–ª–∏ llm_analysis –ø–µ—Ä–µ–¥–∞–Ω:
        - ad_percentage –∏–∑ LLM –∑–∞–º–µ–Ω—è–µ—Ç keyword-based ad_load (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π)
        - bot_percentage –∏–∑ LLM –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ comments.bot_info
    """
    breakdown = breakdown_data.get('breakdown', {})

    # v39.0: –ò–∑–≤–ª–µ–∫–∞–µ–º LLM –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    llm_ad_percentage = None
    llm_bot_percentage = None
    if llm_analysis:
        llm_ad_percentage = llm_analysis.get('ad_percentage')
        llm_bot_percentage = llm_analysis.get('bot_percentage')

    categories = breakdown_data.get('categories', {})

    # v62.5: KEY_MAPPING ‚Äî scorer.py key ‚Üí METRIC_CONFIG key
    # scorer.py produces: reaction_stability, source_diversity
    # METRIC_CONFIG expects: stability, source
    KEY_MAPPING = {
        'reaction_stability': 'stability',
        'source_diversity': 'source',
    }

    # v48.0: –ú–∞–ø–ø–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å labels (Score Metrics - –∏–º–µ—é—Ç points/max)
    METRIC_CONFIG = {
        'quality': {
            'cv_views': 'CV –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤',
            'reach': '–û—Ö–≤–∞—Ç',
            'regularity': '–†–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å',  # v48.0: NEW
            'forward_rate': '–†–µ–ø–æ—Å—Ç—ã',
            # views_decay ‚Üí info_only (points=0, max=0)
        },
        'engagement': {
            'comments': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏',
            'er_trend': '–¢—Ä–µ–Ω–¥ ER',  # v48.0: NEW (–∑–∞–º–µ–Ω–∏–ª er_variation)
            'reaction_rate': '–†–µ–∞–∫—Ü–∏–∏',
            'reaction_stability': '–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å ER',
        },
        'reputation': {
            # v34.0: verified —É–±—Ä–∞–Ω - –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –∫–∞–∫ –≥–∞–ª–æ—á–∫–∞ –Ω–∞ ScoreRing
            'age': '–í–æ–∑—Ä–∞—Å—Ç',
            'premium': '–ü—Ä–µ–º–∏—É–º—ã',
            'source_diversity': '–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å',
        },
    }

    # v23.0: Info Metrics config —Å thresholds –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
    # –≠—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –≤–ª–∏—è—é—Ç –Ω–∞ Trust Factor, –Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ
    INFO_METRICS_CONFIG = {
        'quality': {
            'ad_load': {
                'label': '–†–µ–∫–ª. –Ω–∞–≥—Ä—É–∑–∫–∞',
                'value_key': 'value',  # –ü–æ–ª–µ –≤ breakdown
                'format': 'percent',
                'thresholds': {
                    'good': (0, 10),      # 0-10% = —Ö–æ—Ä–æ—à–æ
                    'warning': (10, 30),  # 10-30% = –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
                    'bad': (30, 100),     # >30% = –ø–ª–æ—Ö–æ
                },
                'invert': False,  # –ú–µ–Ω—å—à–µ = –ª—É—á—à–µ
            },
            'activity': {
                'label': '–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å',
                'source_key': 'posting_frequency',  # v25.0: –±–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ –∏–∑ posting_frequency
                'value_key': 'posts_per_day',
                'format': 'posts_day_smart',  # v25.0: —É–º–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                'thresholds': {
                    # v25.0: –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø–æ—Ä–æ–≥–∏ - —Ä–µ–¥–∫–æ –ø–ª–æ—Ö–æ, –º–Ω–æ–≥–æ —Ç–æ–∂–µ –ø–ª–æ—Ö–æ
                    'bad_low': (0, 0.14),       # < 1/–Ω–µ–¥–µ–ª—è = –º—ë—Ä—Ç–≤—ã–π –∫–∞–Ω–∞–ª
                    'warning_low': (0.14, 0.5), # 1-3/–Ω–µ–¥–µ–ª—è = —Ä–µ–¥–∫–æ
                    'good': (0.5, 8),           # 0.5-8/–¥–µ–Ω—å = –∞–∫—Ç–∏–≤–Ω—ã–π
                    'warning_high': (8, 15),    # 8-15/–¥–µ–Ω—å = –æ—á–µ–Ω—å –∞–∫—Ç–∏–≤–Ω—ã–π
                    'bad_high': (15, 1000),     # >15/–¥–µ–Ω—å = —Å–ø–∞–º
                },
            },
        },
        'reputation': {
            # v25.0: posting_frequency –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω –≤ quality –∫–∞–∫ 'activity'
            'private_links': {
                'label': '–ü—Ä–∏–≤–∞—Ç–Ω—ã–µ',
                'value_key': 'private_ratio',
                'format': 'ratio_percent',  # v23.0: ratio (0.0-1.0) -> percent
                'thresholds': {
                    'good': (0, 0.2),      # 0-20% = –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                    'warning': (0.2, 0.5), # 20-50% = –º–Ω–æ–≥–æ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö
                    'bad': (0.5, 1.0),     # >50% = –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
                },
                'invert': False,
            },
        },
    }

    def get_info_metric_status(value: float, config: dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å info metric –ø–æ thresholds."""
        thresholds = config.get('thresholds', {})

        # v25.0: –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø–æ—Ä–æ–≥–∏ (bad_low, warning_low, good, warning_high, bad_high)
        if 'bad_low' in thresholds:
            if thresholds['bad_low'][0] <= value < thresholds['bad_low'][1]:
                return 'bad'
            if 'warning_low' in thresholds and thresholds['warning_low'][0] <= value < thresholds['warning_low'][1]:
                return 'warning'
            if thresholds['good'][0] <= value < thresholds['good'][1]:
                return 'good'
            if 'warning_high' in thresholds and thresholds['warning_high'][0] <= value < thresholds['warning_high'][1]:
                return 'warning'
            if 'bad_high' in thresholds and value >= thresholds['bad_high'][0]:
                return 'bad'
            return 'warning'

        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª–∏—à–∫–æ–º —Ä–µ–¥–∫–∏–π –ø–æ—Å—Ç–∏–Ω–≥)
        special = config.get('special', {})
        for status, (min_val, max_val) in special.items():
            if min_val <= value < max_val:
                return status

        for status, (min_val, max_val) in thresholds.items():
            if min_val <= value < max_val:
                return status

        return 'warning'  # Default

    def format_info_value(value: float, fmt: str, config: dict = None) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ info metric –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        if fmt == 'percent':
            return f"{value:.0f}%"
        elif fmt == 'ratio_percent':
            # v23.0: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ratio (0.0-1.0) –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            return f"{value * 100:.0f}%"
        elif fmt == 'cv':
            return f"CV {value:.0f}%"
        elif fmt == 'posts_day':
            if value < 1:
                return f"{value:.1f}/–¥–µ–Ω—å"
            else:
                return f"{value:.0f}/–¥–µ–Ω—å"
        elif fmt == 'posts_day_smart':
            # v25.0: –£–º–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ —É–¥–æ–±–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü–∞—Ö
            if value < 0.14:  # < 1/–Ω–µ–¥–µ–ª—è
                posts_per_month = value * 30
                if posts_per_month < 1:
                    return "< 1/–º–µ—Å"
                return f"{posts_per_month:.0f}/–º–µ—Å"
            elif value < 1:  # < 1/–¥–µ–Ω—å
                posts_per_week = value * 7
                return f"{posts_per_week:.1f}/–Ω–µ–¥"
            else:
                return f"{value:.1f}/–¥–µ–Ω—å"
        return str(value)

    result = {}

    for cat_key, metrics in METRIC_CONFIG.items():
        cat_data = categories.get(cat_key, {})

        items = {}
        calculated_max = 0  # v22.2: –°—É–º–º–∞ max –≤—Å–µ—Ö items (—É—á–∏—Ç—ã–≤–∞–µ—Ç floating weights)

        for metric_key, label in metrics.items():
            # v62.5: KEY_MAPPING maps scorer.py keys ‚Üí METRIC_CONFIG keys
            source_key = metric_key
            for scorer_key, config_key in KEY_MAPPING.items():
                if config_key == metric_key and scorer_key in breakdown:
                    source_key = scorer_key
                    break

            metric_data = breakdown.get(source_key, breakdown.get(metric_key, {}))

            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è (scorer.py –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 'points', UI –æ–∂–∏–¥–∞–µ—Ç 'score')
            score_val = metric_data.get('points', metric_data.get('score', 0))
            max_val = metric_data.get('max', 0)

            # v22.1: –ï—Å–ª–∏ max=0, –∑–Ω–∞—á–∏—Ç –º–µ—Ç—Ä–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞ (floating weights)
            # –ù–∞–ø—Ä–∏–º–µ—Ä, reaction_rate=0 –∫–æ–≥–¥–∞ —Ä–µ–∞–∫—Ü–∏–∏ –≤—ã–∫–ª—é—á–µ–Ω—ã –Ω–∞ –∫–∞–Ω–∞–ª–µ
            if max_val == 0 and metric_key in ('reaction_rate', 'comments'):
                item_data = {
                    'score': 0,
                    'max': 0,
                    'label': label,
                    'value': '–æ—Ç–∫–ª.',  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –º–µ—Ç—Ä–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞
                    'disabled': True,
                }
                items[metric_key] = item_data
                continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º human-readable value –µ—Å–ª–∏ –µ—Å—Ç—å
            value = None
            if 'value' in metric_data:
                raw_value = metric_data['value']
                if metric_key == 'verified':
                    value = '–î–∞' if raw_value else '–ù–µ—Ç'
                elif metric_key == 'age':
                    # –í–æ–∑—Ä–∞—Å—Ç –≤ –¥–Ω—è—Ö -> —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
                    days = raw_value if isinstance(raw_value, (int, float)) else 0
                    if days >= 365 * 2:
                        value = f"{int(days / 365)} –≥–æ–¥–∞"
                    elif days >= 365:
                        value = "1 –≥–æ–¥"
                    elif days >= 30:
                        value = f"{int(days / 30)} –º–µ—Å."
                    else:
                        value = f"{int(days)} –¥–Ω."
                elif metric_key == 'reaction_stability':
                    # v58.2: CV (–∫–æ—ç—Ñ. –≤–∞—Ä–∏–∞—Ü–∏–∏) - —á–µ–º –Ω–∏–∂–µ, —Ç–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ
                    # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (257.8% –≤–≤–æ–¥–∏—Ç –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ)
                    cv = raw_value if isinstance(raw_value, (int, float)) else 0
                    if cv < 0.5:
                        value = '–≤—ã—Å–æ–∫–∞—è'
                    elif cv < 1.0:
                        value = '—Å—Ä–µ–¥–Ω—è—è'
                    else:
                        value = '–Ω–∏–∑–∫–∞—è'
                elif metric_key == 'premium':
                    # v58.2: premium_ratio –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –∞—É–¥–∏—Ç–æ—Ä–∏–∏
                    if isinstance(raw_value, (int, float)) and raw_value > 0:
                        value = f"{raw_value:.1f}%"
                    else:
                        value = '0%'
                elif isinstance(raw_value, float):
                    value = f"{raw_value:.1f}%"

            item_data = {
                'score': score_val,
                'max': max_val,
                'label': label,
            }
            if value:
                item_data['value'] = value

            # v39.0: –î–æ–±–∞–≤–ª—è–µ–º bot_percentage –≤ comments –µ—Å–ª–∏ –µ—Å—Ç—å LLM –¥–∞–Ω–Ω—ã–µ
            if metric_key == 'comments' and llm_bot_percentage is not None:
                bot_pct = int(llm_bot_percentage)
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å: <20% = good, 20-50% = warning, >50% = bad
                if bot_pct <= 20:
                    bot_status = 'good'
                elif bot_pct <= 50:
                    bot_status = 'warning'
                else:
                    bot_status = 'bad'
                item_data['bot_info'] = {
                    'value': f'{bot_pct}% –±–æ—Ç—ã',
                    'status': bot_status,
                    'llm_source': True,
                }

            items[metric_key] = item_data
            calculated_max += max_val  # v22.2: –°—É–º–º–∏—Ä—É–µ–º max –∫–∞–∂–¥–æ–≥–æ item

        # v23.0: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º Info Metrics –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        info_metrics = {}
        cat_info_config = INFO_METRICS_CONFIG.get(cat_key, {})

        for info_key, config in cat_info_config.items():
            # v39.0: –î–ª—è ad_load ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM ad_percentage –µ—Å–ª–∏ –µ—Å—Ç—å (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π)
            if info_key == 'ad_load' and llm_ad_percentage is not None:
                float_value = float(llm_ad_percentage)
                status = get_info_metric_status(float_value, config)
                formatted_value = f"{float_value:.0f}%"
                bar_percent = 100 if status == 'good' else 60 if status == 'warning' else 20

                info_metrics[info_key] = {
                    'score': 0,
                    'max': 0,
                    'value': formatted_value,
                    'label': config['label'] + ' (AI)',  # –ú–∞—Ä–∫–∏—Ä—É–µ–º –∫–∞–∫ AI
                    'status': status,
                    'bar_percent': bar_percent,
                    'raw_value': float_value,
                    'llm_source': True,  # v39.0: –ø–æ–º–µ—á–∞–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –æ—Ç LLM
                }
                continue

            # v25.0: source_key –ø–æ–∑–≤–æ–ª—è–µ—Ç –±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥—Ä—É–≥–æ–≥–æ –∫–ª—é—á–∞ breakdown
            source_key = config.get('source_key', info_key)
            info_data = breakdown.get(source_key, {})
            if not info_data:
                continue

            value_key = config.get('value_key', 'value')
            raw_value = info_data.get(value_key)

            if raw_value is None:
                continue

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float
            try:
                float_value = float(raw_value)
            except (TypeError, ValueError):
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            status = get_info_metric_status(float_value, config)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            formatted_value = format_info_value(float_value, config.get('format', 'percent'), config)

            # v24.0: bar_percent –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ (good=100%, warning=60%, bad=20%)
            bar_percent = 100 if status == 'good' else 60 if status == 'warning' else 20

            info_metrics[info_key] = {
                'score': 0,
                'max': 0,
                'value': formatted_value,
                'label': config['label'],
                'status': status,
                'bar_percent': bar_percent,  # v24.0: –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
                'raw_value': float_value,
            }

        result[cat_key] = {
            'total': cat_data.get('score', 0),
            'max': cat_data.get('max', calculated_max),  # v55.0: –ë–µ—Ä—ë–º –∏–∑ categories, fallback –Ω–∞ —Å—É–º–º—É items
            'items': items,
        }

        # v23.0: –î–æ–±–∞–≤–ª—è–µ–º info_metrics —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        if info_metrics:
            result[cat_key]['info_metrics'] = info_metrics

    return result


def estimate_trust_penalties(trust_factor: float, score: int) -> list:
    """
    v7.0: –û—Ü–µ–Ω–∏–≤–∞–µ—Ç trust penalties –Ω–∞ –æ—Å–Ω–æ–≤–µ trust_factor.

    –ï—Å–ª–∏ trust_factor < 1.0, –∑–Ω–∞—á–∏—Ç –±—ã–ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã —à—Ç—Ä–∞—Ñ—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã.
    """
    penalties = []

    if trust_factor >= 1.0:
        return penalties

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é trust_factor
    if trust_factor <= 0.3:
        penalties.append({
            'name': '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫',
            'multiplier': trust_factor,
            'description': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å—ë–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞–∫—Ä—É—Ç–∫–∏'
        })
    elif trust_factor <= 0.5:
        penalties.append({
            'name': '–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫',
            'multiplier': trust_factor,
            'description': '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –∫–∞–Ω–∞–ª–µ'
        })
    elif trust_factor <= 0.7:
        penalties.append({
            'name': '–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫',
            'multiplier': trust_factor,
            'description': '–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤—ã–∑—ã–≤–∞—é—Ç —Å–æ–º–Ω–µ–Ω–∏—è'
        })
    elif trust_factor < 0.9:
        penalties.append({
            'name': '–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∏—Å–∫',
            'multiplier': trust_factor,
            'description': '–ù–µ–±–æ–ª—å—à–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º—ã'
        })
    else:
        penalties.append({
            'name': '–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫',
            'multiplier': trust_factor,
            'description': '–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è'
        })

    return penalties


# v52.2: –ù–∞–∑–≤–∞–Ω–∏—è —à—Ç—Ä–∞—Ñ–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
PENALTY_NAMES = {
    'id_clustering': '–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ID',
    'geo_dc': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ',
    'premium': '–ù–µ—Ç –ø—Ä–µ–º–∏—É–º–æ–≤',
    'hidden_comments': '–°–∫—Ä—ã—Ç—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏',
    'conviction': '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã',
    'hollow_views': '–ü—É—Å—Ç—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã',
    'zombie_engagement': '–ú—ë—Ä—Ç–≤–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å',
    'satellite': '–ö–∞–Ω–∞–ª-—Å–∞—Ç–µ–ª–ª–∏—Ç',
    'ghost_channel': '–ö–∞–Ω–∞–ª-–ø—Ä–∏–∑—Ä–∞–∫',
    'zombie_audience': '–ó–æ–º–±–∏-–∞—É–¥–∏—Ç–æ—Ä–∏—è',
    'member_discrepancy': '–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤',
    'bot_wall': 'Bot Wall',
    'budget_cliff': '–û–±—Ä—ã–≤ –±—é–¥–∂–µ—Ç–∞',
    'dying_engagement': '–£–º–∏—Ä–∞—é—â–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å',
    'posting_frequency': '–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—Å—Ç–∏–Ω–≥–∞',
    'private_links': '–ü—Ä–∏–≤–∞—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏',
    'reaction_flatness': '–ü–ª–æ—Å–∫–∏–µ —Ä–µ–∞–∫—Ü–∏–∏',
    # v60.0: Added missing penalties
    'spam_posting': '–°–ø–∞–º-–ø–æ—Å—Ç–∏–Ω–≥',
    'scam_network': '–°–∫–∞–º-—Å–µ—Ç—å',
}


def extract_trust_penalties_from_details(trust_details: dict) -> list:
    """
    v52.2: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç trust_details –∏–∑ scorer.py –≤ —Ñ–æ—Ä–º–∞—Ç trust_penalties –¥–ª—è UI.

    Args:
        trust_details: dict –≤–∏–¥–∞ {'penalty_key': {'multiplier': X, 'reason': '...'}, ...}

    Returns:
        list of {'name': str, 'multiplier': float, 'description': str}
    """
    if not trust_details:
        return []

    penalties = []
    for key, details in trust_details.items():
        if not isinstance(details, dict):
            continue

        multiplier = details.get('multiplier', 1.0)
        if multiplier >= 1.0:
            continue  # –ù–µ —à—Ç—Ä–∞—Ñ

        name = PENALTY_NAMES.get(key, key.replace('_', ' ').title())
        reason = details.get('reason', '')

        penalties.append({
            'name': name,
            'multiplier': multiplier,
            'description': reason
        })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ multiplier (—Å–∞–º—ã–µ —Å–µ—Ä—å—ë–∑–Ω—ã–µ –ø–µ—Ä–≤—ã–µ)
    penalties.sort(key=lambda x: x['multiplier'])

    return penalties


def extract_llm_penalties(llm_analysis: dict) -> list:
    """
    v60.3: –ò–∑–≤–ª–µ–∫–∞–µ—Ç LLM —à—Ç—Ä–∞—Ñ—ã (–±–æ—Ç—ã, —Ä–µ–∫–ª–∞–º–∞) –∏–∑ llm_analysis.

    Args:
        llm_analysis: dict —Å –ø–æ–ª—è–º–∏ bot_percentage, ad_percentage, bot_mult, ad_mult

    Returns:
        list of {'name': str, 'multiplier': float, 'description': str}
    """
    if not llm_analysis:
        return []

    penalties = []

    # Bot penalty
    bot_mult = llm_analysis.get('bot_mult', 1.0)
    bot_pct = llm_analysis.get('bot_percentage', 0)
    if bot_mult < 1.0 and bot_pct:
        penalties.append({
            'name': '–ë–æ—Ç—ã –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö',
            'multiplier': bot_mult,
            'description': f'{bot_pct}% –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ—Ç –±–æ—Ç–æ–≤'
        })

    # Ad penalty
    ad_mult = llm_analysis.get('ad_mult', 1.0)
    ad_pct = llm_analysis.get('ad_percentage', 0)
    if ad_mult < 1.0 and ad_pct:
        penalties.append({
            'name': '–†–µ–∫–ª–∞–º–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞',
            'multiplier': ad_mult,
            'description': f'{ad_pct}% –ø–æ—Å—Ç–æ–≤ ‚Äî —Ä–µ–∫–ª–∞–º–∞'
        })

    return penalties


def _build_trust_penalties(trust_details: dict, breakdown: dict, trust_factor: float, score: int) -> list:
    """
    v60.3: –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —à—Ç—Ä–∞—Ñ—ã: forensic (trust_details) + LLM (bot/ad).
    """
    penalties = []

    # 1. Forensic penalties –∏–∑ trust_details
    if trust_details:
        penalties.extend(extract_trust_penalties_from_details(trust_details))

    # 2. LLM penalties –∏–∑ breakdown
    if breakdown:
        llm_data = breakdown.get('ll', breakdown.get('llm_analysis', {}))
        if llm_data:
            penalties.extend(extract_llm_penalties(llm_data))

    # 3. Fallback –µ—Å–ª–∏ –Ω–µ—Ç —à—Ç—Ä–∞—Ñ–æ–≤ –Ω–æ trust < 1.0
    if not penalties and trust_factor < 1.0:
        penalties = estimate_trust_penalties(trust_factor, score)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ multiplier (—Å–∞–º—ã–µ —Å–µ—Ä—å—ë–∑–Ω—ã–µ –ø–µ—Ä–≤—ã–µ)
    if penalties:
        penalties.sort(key=lambda x: x.get('multiplier', 1.0))

    return penalties


def generate_recommendations(
    score: int,
    verdict: str,
    trust_factor: float,
    category: Optional[str],
    members: int,
    cpm_min: Optional[int],
    cpm_max: Optional[int],
    breakdown: Optional[dict] = None
) -> List[Recommendation]:
    """
    v8.0: –£–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ breakdown –º–µ—Ç—Ä–∏–∫.
    –ù–µ –ø—Ä–æ—Å—Ç–æ "–æ—Ç–ª–∏—á–Ω—ã–π –∫–∞–Ω–∞–ª", –∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã.
    """
    recs = []

    # v10.1: Price recommendation REMOVED - now shown in Hero section inline

    # 2. –ê–Ω–∞–ª–∏–∑ breakdown ‚Äî —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
    if breakdown:
        # v54.1: –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
        q = breakdown.get('quality', {})
        e = breakdown.get('engagement', {})
        r = breakdown.get('reputation', {})
        quality_pct = (q['total'] / q['max']) * 100 if q.get('max', 0) > 0 else 0
        engagement_pct = (e['total'] / e['max']) * 100 if e.get('max', 0) > 0 else 0
        reputation_pct = (r['total'] / r['max']) * 100 if r.get('max', 0) > 0 else 0

        strengths = []
        if quality_pct >= 70:
            strengths.append("–∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        if engagement_pct >= 70:
            strengths.append("–≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å")
        if reputation_pct >= 80:
            strengths.append("—Ä–µ–ø—É—Ç–∞—Ü–∏—è")
        if trust_factor >= 0.9:
            strengths.append("–¥–æ–≤–µ—Ä–∏–µ")

        if strengths:
            recs.append(Recommendation(
                type="success",
                icon="üí™",
                text=f"–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: {', '.join(strengths)}"
            ))

        # 3. –ê–Ω–∞–ª–∏–∑ breakdown ‚Äî —á—Ç–æ —É–ª—É—á—à–∏—Ç—å
        weaknesses = []
        if quality_pct < 50:
            weaknesses.append("–∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤")
        if engagement_pct < 50:
            weaknesses.append("–≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å")
        if reputation_pct < 50:
            weaknesses.append("—Ä–µ–ø—É—Ç–∞—Ü–∏—è")
        if trust_factor < 0.7:
            weaknesses.append(f"–¥–æ–≤–µ—Ä–∏–µ (√ó{trust_factor:.2f})")

        if weaknesses and verdict not in ["EXCELLENT", "GOOD"]:
            recs.append(Recommendation(
                type="warning",
                icon="‚ö†Ô∏è",
                text=f"–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: {', '.join(weaknesses)}"
            ))

    # 4. –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã
    if category:
        premium_cats = {"CRYPTO": "–∫—Ä–∏–ø—Ç–æ", "FINANCE": "—Ñ–∏–Ω–∞–Ω—Å—ã", "REAL_ESTATE": "–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å", "BUSINESS": "–±–∏–∑–Ω–µ—Å"}
        tech_cats = {"TECH": "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "AI_ML": "–ò–ò/ML"}

        if category in premium_cats:
            recs.append(Recommendation(
                type="tip",
                icon="üíé",
                text=f"{premium_cats[category].capitalize()} ‚Äî –ø—Ä–µ–º–∏—É–º —Å–µ–≥–º–µ–Ω—Ç —Å –≤—ã—Å–æ–∫–∏–º CPM"
            ))
        elif category in tech_cats:
            recs.append(Recommendation(
                type="tip",
                icon="üñ•Ô∏è",
                text=f"{tech_cats[category]} ‚Äî –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è IT/SaaS –ø—Ä–æ–¥—É–∫—Ç–æ–≤"
            ))

    # 5. –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
    if verdict == "EXCELLENT" and trust_factor >= 0.9:
        recs.append(Recommendation(
            type="success",
            icon="‚úÖ",
            text="–ö–∞–Ω–∞–ª –≥–æ—Ç–æ–≤ –∫ —Ä–µ–∫–ª–∞–º–µ –±–µ–∑ –æ–≥–æ–≤–æ—Ä–æ–∫"
        ))
    elif verdict == "GOOD" and trust_factor >= 0.8:
        recs.append(Recommendation(
            type="tip",
            icon="üëç",
            text="–•–æ—Ä–æ—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è —Ä–µ–∫–ª–∞–º–Ω—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π"
        ))
    elif verdict in ["HIGH_RISK", "SCAM"]:
        recs.append(Recommendation(
            type="warning",
            icon="üö´",
            text="–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫! –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —Ä–µ–∫–ª–∞–º—ã"
        ))

    # 6. –†–∞–∑–º–µ—Ä –∫–∞–Ω–∞–ª–∞ ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if members > 100000 and verdict in ["EXCELLENT", "GOOD"]:
        recs.append(Recommendation(
            type="tip",
            icon="üì¢",
            text="–ö—Ä—É–ø–Ω—ã–π –∫–∞–Ω–∞–ª ‚Äî –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤"
        ))
    elif members < 5000 and score >= 70:
        recs.append(Recommendation(
            type="tip",
            icon="üéØ",
            text="–ú–∏–∫—Ä–æ-–∫–∞–Ω–∞–ª —Å –≤—ã—Å–æ–∫–∏–º score ‚Äî —Ç–æ—á–µ—á–Ω–∞—è –ª–æ—è–ª—å–Ω–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è"
        ))

    return recs[:4]  # –ú–∞–∫—Å–∏–º—É–º 4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏


def safe_int(value, default=0) -> int:
    """Safely convert value to int."""
    if value is None:
        return default
    try:
        return int(value)
    except (ValueError, TypeError):
        return default


def safe_float(value, default=1.0) -> float:
    """Safely convert value to float."""
    if value is None:
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        return default


def extract_quick_stats_from_breakdown(breakdown: dict) -> dict:
    """
    v54.0: –ò–∑–≤–ª–µ–∫–∞–µ—Ç quick_stats –∏–∑ breakdown (—Å–∂–∞—Ç—ã–π –∏–ª–∏ –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç).

    –°–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç (v1):
      re = [reach_value, points]
      rr = [reaction_rate_value, points]
      co = ["enabled (avg X.X)", points]

    –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç:
      reach = {'value': X, 'points': Y, 'max': Z}
      reaction_rate = {'value': X, 'points': Y, 'max': Z}
      comments = {'value': X, 'points': Y, 'max': Z}
    """
    quick_stats = {'reach': 0, 'err': 0, 'comments_avg': 0}

    if not breakdown:
        return quick_stats

    # Reach - –æ—Ö–≤–∞—Ç –≤ %
    # –°–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç: re = [value, points]
    re_data = breakdown.get('re')
    if isinstance(re_data, list) and len(re_data) >= 1:
        quick_stats['reach'] = round(float(re_data[0]), 1)
    # –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: reach = {'value': X, ...}
    elif 'reach' in breakdown:
        reach_data = breakdown.get('reach')
        if isinstance(reach_data, dict) and 'value' in reach_data:
            quick_stats['reach'] = round(float(reach_data['value']), 1)
        elif isinstance(reach_data, (int, float)):
            quick_stats['reach'] = round(float(reach_data), 1)

    # ERR / Reaction Rate - engagement rate –≤ %
    # –°–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç: rr = [value, points]
    rr = breakdown.get('rr')
    if isinstance(rr, list) and len(rr) >= 1:
        quick_stats['err'] = round(float(rr[0]), 2)
    # –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: reaction_rate = {'value': X, ...}
    elif 'reaction_rate' in breakdown:
        rr_data = breakdown.get('reaction_rate')
        if isinstance(rr_data, dict) and 'value' in rr_data:
            quick_stats['err'] = round(float(rr_data['value']), 2)
        elif isinstance(rr_data, (int, float)):
            quick_stats['err'] = round(float(rr_data), 2)

    # Comments avg - —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
    # –°–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç: co = ["enabled (avg X.X)", points]
    co = breakdown.get('co')
    if isinstance(co, list) and len(co) >= 1:
        co_value = co[0]
        if isinstance(co_value, str) and 'avg' in co_value:
            match = re.search(r'avg\s+([\d.]+)', co_value)
            if match:
                quick_stats['comments_avg'] = round(float(match.group(1)), 1)
    # –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: comments = {'value': X, ...}
    elif 'comments' in breakdown:
        co_data = breakdown.get('comments')
        if isinstance(co_data, dict) and 'value' in co_data:
            val = co_data['value']
            if isinstance(val, str) and 'avg' in val:
                match = re.search(r'avg\s+([\d.]+)', val)
                if match:
                    quick_stats['comments_avg'] = round(float(match.group(1)), 1)
            elif isinstance(val, (int, float)):
                quick_stats['comments_avg'] = round(float(val), 1)

    return quick_stats


# v22.0: –ö—ç—à –¥–ª—è —Ñ–æ—Ç–æ –∫–∞–Ω–∞–ª–æ–≤ (in-memory, –¥–æ 1000 –∫–∞–Ω–∞–ª–æ–≤)
# v48.0: –î–æ–±–∞–≤–ª–µ–Ω TTL –¥–ª—è –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
import time
_photo_cache: dict = {}  # {username: (bytes, timestamp)}
_PHOTO_CACHE_MAX = 1000
_PHOTO_CACHE_TTL = 3600  # 1 —á–∞—Å


def _cache_cleanup():
    """–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ TTL."""
    now = time.time()
    expired = [k for k, (_, ts) in _photo_cache.items() if now - ts > _PHOTO_CACHE_TTL]
    for k in expired:
        del _photo_cache[k]


@app.get("/api/photo/{username}")
async def get_channel_photo(username: str):
    """
    v22.0: –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≤–∞—Ç–∞—Ä–∫—É –∫–∞–Ω–∞–ª–∞ –∏–∑ Telegram.

    –§–æ—Ç–æ –∫—ç—à–∏—Ä—É—é—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.
    –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å —Ñ–æ—Ç–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 404.
    """
    username = username.lower().lstrip('@')

    # v48.1: –í–∞–ª–∏–¥–∞—Ü–∏—è username
    if not USERNAME_REGEX.match(username):
        raise HTTPException(status_code=400, detail="Invalid username format")

    # v48.0: –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π
    _cache_cleanup()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (—Å TTL)
    if username in _photo_cache:
        photo_bytes, ts = _photo_cache[username]
        if time.time() - ts < _PHOTO_CACHE_TTL:
            return Response(content=photo_bytes, media_type="image/jpeg")

    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ë–î (—Å—Ç–∞—Ä—ã–µ –∫–∞–Ω–∞–ª—ã —Å photo_url)
    if db:
        channel = db.get_channel(username)
        if channel and channel.photo_url and channel.photo_url.startswith('data:image'):
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
            import base64
            try:
                b64_data = channel.photo_url.split(',')[1]
                photo_bytes = base64.b64decode(b64_data)

                # –ö—ç—à–∏—Ä—É–µ–º —Å TTL
                if len(_photo_cache) < _PHOTO_CACHE_MAX:
                    _photo_cache[username] = (photo_bytes, time.time())

                return Response(content=photo_bytes, media_type="image/jpeg")
            except Exception:
                pass

    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ Telegram Bot API
    bot_token = os.getenv("BOT_TOKEN")
    if not bot_token:
        raise HTTPException(status_code=500, detail="BOT_TOKEN not configured")

    try:
        async with httpx.AsyncClient() as client:
            # 1. –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
            chat_resp = await client.get(
                f"https://api.telegram.org/bot{bot_token}/getChat",
                params={"chat_id": f"@{username}"},
                timeout=10.0
            )
            chat_data = chat_resp.json()

            if not chat_data.get("ok"):
                raise HTTPException(status_code=404, detail="Channel not found")

            chat = chat_data.get("result", {})
            photo = chat.get("photo")

            if not photo:
                raise HTTPException(status_code=404, detail="Channel has no photo")

            # 2. –ü–æ–ª—É—á–∞–µ–º file_path –¥–ª—è big_file_id
            big_file_id = photo.get("big_file_id")
            if not big_file_id:
                raise HTTPException(status_code=404, detail="No photo file_id")

            file_resp = await client.get(
                f"https://api.telegram.org/bot{bot_token}/getFile",
                params={"file_id": big_file_id},
                timeout=10.0
            )
            file_data = file_resp.json()

            if not file_data.get("ok"):
                raise HTTPException(status_code=404, detail="Cannot get file info")

            file_path = file_data.get("result", {}).get("file_path")
            if not file_path:
                raise HTTPException(status_code=404, detail="No file_path")

            # 3. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
            photo_resp = await client.get(
                f"https://api.telegram.org/file/bot{bot_token}/{file_path}",
                timeout=30.0
            )

            if photo_resp.status_code != 200:
                raise HTTPException(status_code=404, detail="Cannot download photo")

            photo_bytes = photo_resp.content

            # –ö—ç—à–∏—Ä—É–µ–º —Å TTL
            if len(_photo_cache) < _PHOTO_CACHE_MAX:
                _photo_cache[username] = (photo_bytes, time.time())

            return Response(content=photo_bytes, media_type="image/jpeg")

    except HTTPException:
        raise
    except Exception as e:
        # v65.1: –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"[PHOTO ERROR] {username}: {type(e).__name__}: {e}")
        raise HTTPException(status_code=500, detail="Internal error")


# v54.0: –ö—ç—à —Ñ–æ—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
_user_photo_cache: dict[int, tuple[bytes, float]] = {}


@app.get("/api/user/photo/{user_id}")
async def get_user_photo(user_id: int):
    """
    v54.0: –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≤–∞—Ç–∞—Ä–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ Telegram.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç getUserProfilePhotos API.
    –§–æ—Ç–æ –∫—ç—à–∏—Ä—É—é—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.
    """
    # –í–∞–ª–∏–¥–∞—Ü–∏—è user_id
    if user_id <= 0:
        raise HTTPException(status_code=400, detail="Invalid user_id")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if user_id in _user_photo_cache:
        photo_bytes, ts = _user_photo_cache[user_id]
        if time.time() - ts < _PHOTO_CACHE_TTL:
            return Response(content=photo_bytes, media_type="image/jpeg")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ Telegram Bot API
    bot_token = os.getenv("BOT_TOKEN")
    if not bot_token:
        raise HTTPException(status_code=500, detail="BOT_TOKEN not configured")

    try:
        async with httpx.AsyncClient() as client:
            # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–æ—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            photos_resp = await client.get(
                f"https://api.telegram.org/bot{bot_token}/getUserProfilePhotos",
                params={"user_id": user_id, "limit": 1},
                timeout=10.0
            )
            photos_data = photos_resp.json()

            if not photos_data.get("ok"):
                raise HTTPException(status_code=404, detail="Cannot get user photos")

            photos = photos_data.get("result", {}).get("photos", [])
            if not photos:
                raise HTTPException(status_code=404, detail="User has no photo")

            # 2. –ë–µ—Ä—ë–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —Ñ–æ—Ç–æ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
            photo_sizes = photos[0]
            if not photo_sizes:
                raise HTTPException(status_code=404, detail="No photo sizes")

            # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ
            big_photo = max(photo_sizes, key=lambda x: x.get("width", 0) * x.get("height", 0))
            file_id = big_photo.get("file_id")

            if not file_id:
                raise HTTPException(status_code=404, detail="No file_id")

            # 3. –ü–æ–ª—É—á–∞–µ–º file_path
            file_resp = await client.get(
                f"https://api.telegram.org/bot{bot_token}/getFile",
                params={"file_id": file_id},
                timeout=10.0
            )
            file_data = file_resp.json()

            if not file_data.get("ok"):
                raise HTTPException(status_code=404, detail="Cannot get file info")

            file_path = file_data.get("result", {}).get("file_path")
            if not file_path:
                raise HTTPException(status_code=404, detail="No file_path")

            # 4. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
            photo_resp = await client.get(
                f"https://api.telegram.org/file/bot{bot_token}/{file_path}",
                timeout=30.0
            )

            if photo_resp.status_code != 200:
                raise HTTPException(status_code=404, detail="Cannot download photo")

            photo_bytes = photo_resp.content

            # –ö—ç—à–∏—Ä—É–µ–º —Å TTL
            if len(_user_photo_cache) < _PHOTO_CACHE_MAX:
                _user_photo_cache[user_id] = (photo_bytes, time.time())

            return Response(content=photo_bytes, media_type="image/jpeg")

    except HTTPException:
        raise
    except Exception:
        raise HTTPException(status_code=500, detail="Internal error")


@app.get("/api/health")
async def health_check():
    """Health check endpoint —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ë–î."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
        if db is None:
            return {"status": "error", "error": "Database not initialized", "version": "1.0.0"}

        stats = db.get_stats()
        return {
            "status": "ok",
            "version": "1.0.0",
            "db": {
                "connected": True,
                "total_channels": stats.get("total", 0),
                "good_channels": stats.get("good", 0)
            }
        }
    except Exception as e:
        return {"status": "error", "error": str(e), "version": "1.0.0"}


@app.get("/api/channels", response_model=ChannelListResponse)
async def get_channels(
    category: Optional[str] = Query(None, description="–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"),
    min_score: int = Query(0, ge=0, le=100),
    max_score: int = Query(100, ge=0, le=100),
    min_members: int = Query(0, ge=0),
    max_members: int = Query(10000000, ge=0),
    min_trust: float = Query(0.0, ge=0.0, le=1.0, description="–ú–∏–Ω. Trust Factor"),
    verdict: Optional[str] = Query(None, description="good_plus = EXCELLENT+GOOD"),
    sort_by: str = Query("score", regex="^(score|members|scanned_at|trust_factor)$"),
    sort_order: str = Query("desc", regex="^(asc|desc)$"),
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π.
    –ù–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã v6.0: min_trust, verdict (good_plus = EXCELLENT + GOOD)
    """
    params = [min_score, max_score, min_members, max_members, min_trust]

    # Base WHERE clause - v33: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏ GOOD –∏ BAD –∫–∞–Ω–∞–ª—ã
    where_clause = """
        WHERE status IN ('GOOD', 'BAD')
          AND score >= ? AND score <= ?
          AND members >= ? AND members <= ?
          AND trust_factor >= ?
    """

    # Verdict filter: good_plus = only EXCELLENT and GOOD
    if verdict == "good_plus":
        where_clause += " AND verdict IN ('EXCELLENT', 'GOOD')"

    if category:
        where_clause += " AND (category = ? OR category_secondary = ?)"
        params.extend([category, category])

    # Count total
    count_query = f"SELECT COUNT(*) FROM channels {where_clause}"
    cursor = db.conn.execute(count_query, params)
    total = safe_int(cursor.fetchone()[0], 0)

    # Main query - v34.0: –¥–æ–±–∞–≤–ª–µ–Ω breakdown_json –¥–ª—è is_verified
    # v58.2: –¥–æ–±–∞–≤–ª–µ–Ω title –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–∞
    query = f"""
        SELECT username, score, verdict, trust_factor, members,
               category, category_secondary, scanned_at, photo_url, category_percent,
               breakdown_json, title
        FROM channels {where_clause}
    """

    # Add sorting and pagination (whitelist approach to prevent SQL injection)
    ALLOWED_SORT_COLUMNS = {"score", "members", "scanned_at", "trust_factor"}
    safe_sort_by = sort_by if sort_by in ALLOWED_SORT_COLUMNS else "score"
    safe_sort_order = "DESC" if sort_order == "desc" else "ASC"
    query += f" ORDER BY {safe_sort_by} {safe_sort_order}"
    query += " LIMIT ? OFFSET ?"
    params.extend([page_size, (page - 1) * page_size])

    cursor = db.conn.execute(query, params)
    rows = cursor.fetchall()

    channels = []
    for row in rows:
        score = safe_int(row[1], 0)
        trust_factor = safe_float(row[3], 1.0)
        members = safe_int(row[4], 0)
        category = row[5]

        # v34.0: –ò–∑–≤–ª–µ–∫–∞–µ–º is_verified –∏–∑ breakdown_json
        is_verified = False
        if row[10]:  # breakdown_json
            try:
                breakdown_data = json.loads(row[10])
                # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≤ breakdown.verified.value –∏–ª–∏ –≤ flags.is_verified
                bd = breakdown_data.get('breakdown', breakdown_data)
                if 'verified' in bd and isinstance(bd['verified'], dict):
                    is_verified = bd['verified'].get('value', False)
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º flags
                flags = breakdown_data.get('flags', {})
                if 'is_verified' in flags:
                    is_verified = flags.get('is_verified', False)
            except (json.JSONDecodeError, KeyError, TypeError):
                pass

        # v13.1: –ò—Å–ø–æ–ª—å–∑—É–µ–º breakdown –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã—Ö —Ü–µ–Ω
        breakdown = estimate_breakdown(score, trust_factor)
        trust_penalties = estimate_trust_penalties(trust_factor, score)
        price_min, price_max = calculate_post_price(
            category, members, trust_factor, score,
            breakdown=breakdown,
            trust_penalties=trust_penalties
        )

        channels.append(ChannelSummary(
            username=str(row[0]) if row[0] else "",
            title=str(row[11]) if row[11] else None,  # v58.2
            score=score,
            verdict=str(row[2]) if row[2] else "",
            trust_factor=trust_factor,
            members=members,
            category=category,
            category_secondary=row[6],
            category_percent=safe_int(row[9], 100) if row[9] else 100,  # v20.0
            scanned_at=str(row[7]) if row[7] else None,
            cpm_min=price_min,
            cpm_max=price_max,
            photo_url=str(row[8]) if row[8] else None,
            is_verified=is_verified,  # v34.0
        ))

    return ChannelListResponse(
        channels=channels,
        total=total,
        page=page,
        page_size=page_size,
        has_more=(page * page_size) < total,
    )


# v59.7: Endpoint –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ –∫–∞–Ω–∞–ª–æ–≤ (–¥–ª—è preview –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ö)
@app.get("/api/channels/count")
async def get_channels_count(
    category: Optional[str] = Query(None, description="–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"),
    min_score: int = Query(0, ge=0, le=100),
    max_score: int = Query(100, ge=0, le=100),
    min_members: int = Query(0, ge=0),
    max_members: int = Query(10000000, ge=0),
    min_trust: float = Query(0.0, ge=0.0, le=1.0, description="–ú–∏–Ω. Trust Factor"),
    verdict: Optional[str] = Query(None, description="good_plus = EXCELLENT+GOOD"),
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º (–±–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è preview –≤ –∫–Ω–æ–ø–∫–µ "–ü–æ–∫–∞–∑–∞—Ç—å X —à—Ç."
    """
    params = [min_score, max_score, min_members, max_members, min_trust]

    where_clause = """
        WHERE status IN ('GOOD', 'BAD')
          AND score >= ? AND score <= ?
          AND members >= ? AND members <= ?
          AND trust_factor >= ?
    """

    if verdict == "good_plus":
        where_clause += " AND verdict IN ('EXCELLENT', 'GOOD')"

    if category:
        where_clause += " AND (category = ? OR category_secondary = ?)"
        params.extend([category, category])

    count_query = f"SELECT COUNT(*) FROM channels {where_clause}"
    cursor = db.conn.execute(count_query, params)
    total = safe_int(cursor.fetchone()[0], 0)

    return {"count": total}


# v61.0: Endpoints export/import/reset —É–¥–∞–ª–µ–Ω—ã
# –ë–î —Ç–µ–ø–µ—Ä—å –∫–æ–ø–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ SCP, —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞


@app.get("/api/channels/{username}")
async def get_channel(username: str, request: Request):
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–∞–Ω–∞–ª–∞ –ø–æ username.
    –ï—Å–ª–∏ –∫–∞–Ω–∞–ª–∞ –Ω–µ—Ç –≤ –±–∞–∑–µ - –≤–µ—Ä–Ω—É—Ç—å 404.

    v23.0: –ß–∏—Ç–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π breakdown_json –∏–∑ –ë–î –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω,
    –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç estimate_breakdown() –∫–∞–∫ fallback.
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Info Metrics (ad_load, regularity, posting_frequency, private_links).
    """
    start_time = time.perf_counter()
    user_id = get_user_id_from_request(request)
    platform = request.headers.get('X-Platform', 'unknown')
    username = username.lower().lstrip("@")

    # v48.2: –í–∞–ª–∏–¥–∞—Ü–∏—è username (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å get_channel_photo)
    if not USERNAME_REGEX.match(username):
        raise HTTPException(status_code=400, detail="Invalid username format")

    # v23.0: –ß–∏—Ç–∞–µ–º breakdown_json –∏–∑ –ë–î (–µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    # v59.3: –î–æ–±–∞–≤–ª–µ–Ω title
    # v59.4: LOWER() –¥–ª—è case-insensitive –ø–æ–∏—Å–∫–∞ (–≤ –ë–î –º–æ–≥—É—Ç –±—ã—Ç—å mixed-case)
    # v59.6: –î–æ–±–∞–≤–ª–µ–Ω avg_views –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Ü–µ–Ω—ã
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º try/except –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ë–î –±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ breakdown_json
    try:
        cursor = db.conn.execute("""
            SELECT username, score, verdict, trust_factor, members,
                   category, category_secondary, scanned_at, status,
                   photo_url, breakdown_json, title, avg_views
            FROM channels
            WHERE LOWER(username) = ?
        """, (username,))
    except Exception:
        # Fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –ë–î –±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ breakdown_json/title/avg_views
        cursor = db.conn.execute("""
            SELECT username, score, verdict, trust_factor, members,
                   category, category_secondary, scanned_at, status
            FROM channels
            WHERE LOWER(username) = ?
        """, (username,))

    row = cursor.fetchone()

    if not row:
        raise HTTPException(status_code=404, detail="–ö–∞–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ")

    score = safe_int(row[1], 0)
    verdict = str(row[2]) if row[2] else ""
    trust_factor = safe_float(row[3], 1.0)
    members = safe_int(row[4], 0)
    category = row[5]

    # v23.0: –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π breakdown –∏–∑ –ë–î
    # v59.3: –î–æ–±–∞–≤–ª–µ–Ω title
    # v59.6: –î–æ–±–∞–≤–ª–µ–Ω avg_views
    breakdown_json_str = row[10] if len(row) > 10 else None
    photo_url = row[9] if len(row) > 9 else None
    title = row[11] if len(row) > 11 else None
    db_avg_views = safe_int(row[12], 0) if len(row) > 12 else None  # v59.6

    # –ü–∞—Ä—Å–∏–º breakdown_json –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    real_breakdown_data = None
    if breakdown_json_str:
        try:
            real_breakdown_data = json.loads(breakdown_json_str)
        except (json.JSONDecodeError, TypeError):
            real_breakdown_data = None

    # v39.0: –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—ã—Ä—ã–µ LLM –¥–∞–Ω–Ω—ã–µ –ü–ï–†–ï–î format_breakdown_for_ui
    # —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –≤ –º–µ—Ç—Ä–∏–∫–∏
    # v40.3: –ò—â–µ–º –≤ –æ–±–æ–∏—Ö –º–µ—Å—Ç–∞—Ö - –∫–æ—Ä–µ–Ω—å –ò –≤–ª–æ–∂–µ–Ω–Ω—ã–π breakdown (–±–∞–≥ crawler.py)
    raw_llm_analysis = None
    if real_breakdown_data:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –∫–æ—Ä–µ–Ω—å (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
        if real_breakdown_data.get('llm_analysis'):
            raw_llm_analysis = real_breakdown_data.get('llm_analysis')
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –≤–ª–æ–∂–µ–Ω–Ω—ã–π –≤ breakdown (—Ç–µ–∫—É—â–∏–π –±–∞–≥ crawler.py)
        elif real_breakdown_data.get('breakdown', {}).get('llm_analysis'):
            raw_llm_analysis = real_breakdown_data.get('breakdown', {}).get('llm_analysis')

    # v54.0: QuickStats –∏–∑ —Å–∂–∞—Ç–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (–î–û –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏!)
    quick_stats = {'reach': 0, 'err': 0, 'comments_avg': 0}
    if real_breakdown_data and real_breakdown_data.get('breakdown'):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è quick_stats
        original_compressed = real_breakdown_data.get('breakdown', {})
        quick_stats = extract_quick_stats_from_breakdown(original_compressed)

    # v23.0: –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π breakdown - —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –µ–≥–æ –¥–ª—è UI
    # v39.0: –ü–µ—Ä–µ–¥–∞—ë–º LLM –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –º–µ—Ç—Ä–∏–∫–∏
    # v58.0: –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—è —Å–∂–∞—Ç—ã—Ö –∫–ª—é—á–µ–π (cv -> cv_views, etc.)
    # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º estimate_breakdown() –∫–∞–∫ fallback
    if real_breakdown_data and real_breakdown_data.get('breakdown'):
        # v58.0: –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä—É–µ–º —Å–∂–∞—Ç—ã–π breakdown
        decompressed = decompress_breakdown(real_breakdown_data.get('breakdown', {}))
        real_breakdown_data['breakdown'] = decompressed
        breakdown = format_breakdown_for_ui(real_breakdown_data, raw_llm_analysis)
        breakdown_source = "database"
    else:
        breakdown = estimate_breakdown(score, trust_factor)
        breakdown_source = "estimated"

    # v39.0: llm_analysis —Ç–µ–ø–µ—Ä—å –ù–ï –æ—Ç–¥–∞—ë–º –æ—Ç–¥–µ–ª—å–Ω–æ ‚Äî –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ breakdown
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ tier/tier_cap –¥–ª—è status banner (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    llm_analysis = None
    if raw_llm_analysis:
        llm_analysis = {
            'tier': raw_llm_analysis.get('tier', 'STANDARD'),
            'tier_cap': raw_llm_analysis.get('tier_cap', 100),
        }

    # v34.0: –ò–∑–≤–ª–µ–∫–∞–µ–º is_verified –∏–∑ breakdown_json
    is_verified = False
    if real_breakdown_data:
        bd = real_breakdown_data.get('breakdown', real_breakdown_data)
        if 'verified' in bd and isinstance(bd['verified'], dict):
            is_verified = bd['verified'].get('value', False)
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º flags
        flags = real_breakdown_data.get('flags', {})
        if 'is_verified' in flags:
            is_verified = flags.get('is_verified', False)

    # v60.3: Trust penalties (forensic + LLM)
    trust_details = {}
    breakdown_for_llm = {}
    if real_breakdown_data:
        bd = real_breakdown_data.get('breakdown', real_breakdown_data)
        trust_details = bd.get('trust_details', {})
        breakdown_for_llm = bd

    trust_penalties = _build_trust_penalties(trust_details, breakdown_for_llm, trust_factor, score)

    # v13.0: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—É —Å –í–°–ï–ú–ò –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–∞–º–∏
    # v59.6: –ü–µ—Ä–µ–¥–∞—ë–º —Ä–µ–∞–ª—å–Ω–æ–µ avg_views –∏–∑ –ë–î
    price_min, price_max = calculate_post_price(
        category, members, trust_factor, score,
        breakdown=breakdown,
        trust_penalties=trust_penalties,
        avg_views=db_avg_views
    )

    # v13.0: –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ price_estimate —Å –í–°–ï–ú–ò –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–∞–º–∏
    # v59.6: –ü–µ—Ä–µ–¥–∞—ë–º —Ä–µ–∞–ª—å–Ω–æ–µ avg_views –∏–∑ –ë–î
    price_estimate = calculate_post_price_details(
        category, members, trust_factor, score,
        breakdown=breakdown,
        trust_penalties=trust_penalties,
        avg_views=db_avg_views
    )

    # v15.0: calculate_post_price_details –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict (fallback –Ω–µ –Ω—É–∂–µ–Ω)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (v8.0: —Å breakdown)
    recommendations = generate_recommendations(
        score=score,
        verdict=verdict,
        trust_factor=trust_factor,
        category=category,
        members=members,
        cpm_min=price_min,
        cpm_max=price_max,
        breakdown=breakdown
    )

    # v62.0: Analytics logging
    asyncio.create_task(log_analytics(
        event_type='channel_view',
        user_id=user_id,
        username=str(row[0]),
        score=score,
        verdict=verdict,
        duration_ms=int((time.perf_counter() - start_time) * 1000),
        platform=platform,
        properties={'members': members, 'category': category}
    ))

    return {
        "username": str(row[0]) if row[0] else "",
        "title": title,  # v59.3: –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
        "score": score,
        "verdict": verdict,
        "trust_factor": trust_factor,
        "members": members,
        "category": category,
        "category_secondary": row[6] if len(row) > 6 else None,
        "category_percent": 100,  # v15.0: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑ –ë–î
        "scanned_at": str(row[7]) if len(row) > 7 and row[7] else None,
        "status": row[8] if len(row) > 8 else "GOOD",
        "photo_url": photo_url,  # v23.0: —á–∏—Ç–∞–µ–º –∏–∑ –ë–î
        "cpm_min": price_min,
        "cpm_max": price_max,
        "recommendations": [r.dict() for r in recommendations],
        "source": "database",
        # v7.0: –ù–æ–≤—ã–µ –ø–æ–ª—è
        "breakdown": breakdown,
        "breakdown_source": breakdown_source,  # v23.0: —É–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
        "trust_penalties": trust_penalties,
        "price_estimate": price_estimate,
        # v38.0: LLM Analysis
        "llm_analysis": llm_analysis,
        # v34.0: Telegram –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        "is_verified": is_verified,
        # v54.0: QuickStats (reach, err, comments_avg)
        "quick_stats": quick_stats,
    }


@app.get("/api/stats", response_model=StatsResponse)
async def get_stats():
    """–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã."""
    stats = db.get_stats()
    return StatsResponse(
        total=stats.get("total", 0),
        good=stats.get("good", 0),
        bad=stats.get("bad", 0),
        waiting=stats.get("waiting", 0),
        error=stats.get("error", 0),
    )


@app.get("/api/stats/categories", response_model=CategoryStatsResponse)
async def get_category_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
    cat_stats = db.get_category_stats()

    categories = []
    total_categorized = 0

    for cat, count in sorted(cat_stats.items(), key=lambda x: x[1], reverse=True):
        if cat == "UNCATEGORIZED":
            continue
        cat_normalized = normalize_category(cat)
        rates = CPM_RATES.get(cat_normalized, {"low": 65, "avg": 130, "high": 270})
        categories.append(CategoryStat(
            category=cat,
            count=count,
            cpm_min=rates["low"],
            cpm_max=rates["high"],
        ))
        total_categorized += count

    uncategorized = cat_stats.get("UNCATEGORIZED", 0)

    return CategoryStatsResponse(
        categories=categories,
        total_categorized=total_categorized,
        uncategorized=uncategorized,
    )


# ============================================================================
# v49.0: LIVE SCAN ENDPOINT
# ============================================================================

@app.post("/api/scan", response_model=ScanResponse)
async def live_scan_channel(request: ScanRequest):
    """
    v49.0: Live scan –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ scanner.

    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –∫–∞–Ω–∞–ª –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ Pyrogram.
    –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: 10-30 —Å–µ–∫—É–Ω–¥.
    """
    username = request.username.lower().lstrip('@')

    # v48.1: –í–∞–ª–∏–¥–∞—Ü–∏—è username
    if not USERNAME_REGEX.match(username):
        return ScanResponse(success=False, error="Invalid username format")

    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º scanner –º–æ–¥—É–ª—å
        from scanner.client import smart_scan_safe, get_client
        from scanner.scorer import calculate_final_score

        # –ü–æ–ª—É—á–∞–µ–º Pyrogram –∫–ª–∏–µ–Ω—Ç
        client = get_client()
        if not client.is_connected:
            await client.start()

        # –°–∫–∞–Ω–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª
        scan_result = await smart_scan_safe(client, username)

        if scan_result.chat is None:
            error_reason = scan_result.channel_health.get("reason", "Channel not found")
            return ScanResponse(success=False, error=error_reason)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º score
        result = calculate_final_score(
            scan_result.chat,
            scan_result.messages,
            scan_result.comments_data,
            scan_result.users,
            scan_result.channel_health
        )

        score = result.get('score', 0)
        verdict = result.get('verdict', 'UNKNOWN')
        trust_factor = result.get('trust_factor', 1.0)
        members = result.get('members', 0)
        categories = result.get('categories', {})
        breakdown = result.get('breakdown', {})
        flags = result.get('flags', {})
        trust_details = result.get('trust_details', {})  # v52.2

        # v52.2: –î–æ–±–∞–≤–ª—è–µ–º trust_details –≤ breakdown
        if trust_details:
            breakdown['trust_details'] = trust_details

        # –§–æ—Ä–º–∏—Ä—É–µ–º breakdown_json
        breakdown_data = {
            'breakdown': breakdown,
            'categories': categories,
            'flags': flags,
        }
        breakdown_json = json.dumps(breakdown_data, ensure_ascii=False)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (upsert)
        from datetime import datetime
        db.conn.execute("""
            INSERT OR REPLACE INTO channels
            (username, score, verdict, trust_factor, members,
             status, scanned_at, breakdown_json)
            VALUES (?, ?, ?, ?, ?, 'GOOD', datetime('now'), ?)
        """, (username, score, verdict, trust_factor, members, breakdown_json))
        db.conn.commit()

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (–∫–∞–∫ get_channel)
        is_verified = flags.get('is_verified', False)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º breakdown –¥–ª—è UI
        ui_breakdown = format_breakdown_for_ui(breakdown_data, None)

        price_min, price_max = calculate_post_price(
            None, members, trust_factor, score,
            breakdown=ui_breakdown
        )

        recommendations = generate_recommendations(
            score=score, verdict=verdict, trust_factor=trust_factor,
            category=None, members=members,
            cpm_min=price_min, cpm_max=price_max,
            breakdown=ui_breakdown
        )

        channel_data = {
            "username": username,
            "score": score,
            "verdict": verdict,
            "trust_factor": trust_factor,
            "members": members,
            "category": None,
            "category_secondary": None,
            "category_percent": 100,
            "scanned_at": datetime.now().isoformat(),
            "cpm_min": price_min,
            "cpm_max": price_max,
            "recommendations": [r.dict() for r in recommendations],
            "breakdown": ui_breakdown,
            # v60.3: Trust penalties —Å —É—á—ë—Ç–æ–º LLM —à—Ç—Ä–∞—Ñ–æ–≤
            "trust_penalties": _build_trust_penalties(trust_details, breakdown, trust_factor, score),
            "is_verified": is_verified,
            "source": "live_scan",
        }

        return ScanResponse(success=True, channel=channel_data)

    except Exception as e:
        import traceback
        traceback.print_exc()
        # v48.2: –ù–µ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏
        return ScanResponse(success=False, error="Scan failed")


# ============================================================================
# v62.0: ANALYTICS ENDPOINTS
# ============================================================================

class EventCreate(BaseModel):
    event_type: str
    user_id: Optional[int] = None
    session_id: Optional[str] = None
    properties: Optional[dict] = None
    platform: Optional[str] = None


@app.post("/api/events")
async def track_event(event: EventCreate, request: Request):
    """v62.0: Endpoint –¥–ª—è frontend event tracking."""
    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á—å user_id –∏–∑ header –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
    user_id = event.user_id or get_user_id_from_request(request)

    asyncio.create_task(log_analytics(
        event_type=event.event_type,
        user_id=user_id,
        properties=event.properties,
        platform=event.platform or request.headers.get('X-Platform', 'unknown')
    ))
    return {"success": True}


@app.get("/api/analytics/summary")
async def get_analytics_summary(days: int = 7):
    """v62.0: –°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥."""
    cursor = db.conn.cursor()

    # DAU –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å
    cursor.execute("""
        SELECT DATE(created_at) as day, COUNT(DISTINCT user_id) as dau
        FROM analytics_events
        WHERE created_at >= datetime('now', ? || ' days')
          AND user_id IS NOT NULL
        GROUP BY DATE(created_at)
        ORDER BY day DESC
    """, (f"-{days}",))
    dau_by_day = {row[0]: row[1] for row in cursor.fetchall()}

    # –°–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
    cursor.execute("""
        SELECT event_type, COUNT(*) as count, AVG(duration_ms) as avg_ms
        FROM analytics_events
        WHERE created_at >= datetime('now', ? || ' days')
        GROUP BY event_type
    """, (f"-{days}",))
    events = {row[0]: {"count": row[1], "avg_ms": round(row[2], 1) if row[2] else None}
              for row in cursor.fetchall()}

    # –¢–æ–ø –∫–∞–Ω–∞–ª–æ–≤
    cursor.execute("""
        SELECT username, COUNT(*) as cnt
        FROM analytics_events
        WHERE event_type IN ('scan_request', 'channel_view')
          AND created_at >= datetime('now', ? || ' days')
          AND username IS NOT NULL
        GROUP BY username ORDER BY cnt DESC LIMIT 10
    """, (f"-{days}",))
    top_channels = [{"username": row[0], "count": row[1]} for row in cursor.fetchall()]

    # –í–æ—Ä–æ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
    cursor.execute("""
        SELECT
            COUNT(DISTINCT CASE WHEN event_type = 'app_open' THEN user_id END) as opens,
            COUNT(DISTINCT CASE WHEN event_type IN ('search_submit', 'channel_view') THEN user_id END) as browse,
            COUNT(DISTINCT CASE WHEN event_type = 'channel_detail' THEN user_id END) as detail
        FROM analytics_events
        WHERE created_at >= datetime('now', ? || ' days')
    """, (f"-{days}",))
    funnel = cursor.fetchone()

    return {
        "period_days": days,
        "dau_by_day": dau_by_day,
        "events": events,
        "top_channels": top_channels,
        "funnel": {"opens": funnel[0], "browse": funnel[1], "detail": funnel[2]} if funnel else {}
    }


# ============================================================================
# v58.0: SCAN REQUEST QUEUE
# ============================================================================

class ScanRequestCreate(BaseModel):
    username: str


class ScanRequestItem(BaseModel):
    id: int
    username: str
    status: str
    created_at: str
    processed_at: Optional[str] = None
    error: Optional[str] = None


class ScanRequestResponse(BaseModel):
    success: bool
    request_id: Optional[int] = None
    message: str


# v61.0: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∑–∞–ø—Ä–æ—Å–æ–≤
REQUESTS_FILE = Path("/root/reklamshik/requests.json")


def _read_requests() -> list:
    """–ß–∏—Ç–∞–µ—Ç requests.json."""
    if not REQUESTS_FILE.exists():
        return []
    try:
        return json.loads(REQUESTS_FILE.read_text())
    except (json.JSONDecodeError, IOError):
        return []


def _write_requests(requests: list):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç requests.json."""
    REQUESTS_FILE.write_text(json.dumps(requests, indent=2, ensure_ascii=False))


@app.post("/api/scan/request", response_model=ScanRequestResponse)
async def create_scan_request(scan_req: ScanRequestCreate, request: Request):
    """
    v61.0: –î–æ–±–∞–≤–ª—è–µ—Ç –∫–∞–Ω–∞–ª –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ.
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ requests.json –¥–ª—è –∑–∞–±–æ—Ä–∞ –ª–æ–∫–∞–ª—å–Ω—ã–º –∫—Ä–∞—É–ª–µ—Ä–æ–º —á–µ—Ä–µ–∑ SCP.
    """
    start_time = time.perf_counter()
    user_id = get_user_id_from_request(request)
    platform = request.headers.get('X-Platform', 'unknown')
    username = scan_req.username.lower().lstrip('@')

    # –í–∞–ª–∏–¥–∞—Ü–∏—è username
    if not USERNAME_REGEX.match(username):
        asyncio.create_task(log_analytics(
            event_type='scan_request',
            user_id=user_id,
            username=username,
            status='error',
            error_message='Invalid username format',
            duration_ms=int((time.perf_counter() - start_time) * 1000),
            platform=platform
        ))
        return ScanRequestResponse(success=False, message="Invalid username format")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω –ª–∏ —É–∂–µ –∫–∞–Ω–∞–ª (—Å –±–∞–ª–ª–∞–º–∏ > 0)
    cursor = db.conn.cursor()
    cursor.execute(
        "SELECT score, status FROM channels WHERE LOWER(username) = ?",
        (username,)
    )
    existing = cursor.fetchone()
    if existing and existing[0] is not None and existing[0] > 0 and existing[1] in ('GOOD', 'BAD'):
        asyncio.create_task(log_analytics(
            event_type='scan_request',
            user_id=user_id,
            username=username,
            score=existing[0],
            status='already_scanned',
            duration_ms=int((time.perf_counter() - start_time) * 1000),
            platform=platform
        ))
        return ScanRequestResponse(
            success=True,
            request_id=0,
            message=f"Channel already scanned (score: {existing[0]})"
        )

    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã
    requests_list = _read_requests()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç –≤ –æ—á–µ—Ä–µ–¥–∏
    existing_usernames = [r.get("username", "").lower() for r in requests_list]
    if username in existing_usernames:
        asyncio.create_task(log_analytics(
            event_type='scan_request',
            user_id=user_id,
            username=username,
            status='already_queued',
            duration_ms=int((time.perf_counter() - start_time) * 1000),
            platform=platform,
            properties={'queue_position': existing_usernames.index(username) + 1}
        ))
        return ScanRequestResponse(
            success=True,
            request_id=len(requests_list),
            message="Already in queue"
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
    requests_list.append({
        "username": username,
        "requested_at": datetime.now().isoformat()
    })
    _write_requests(requests_list)

    asyncio.create_task(log_analytics(
        event_type='scan_request',
        user_id=user_id,
        username=username,
        status='queued',
        duration_ms=int((time.perf_counter() - start_time) * 1000),
        platform=platform,
        properties={'queue_position': len(requests_list)}
    ))

    return ScanRequestResponse(
        success=True,
        request_id=len(requests_list),
        message="Request added to queue"
    )


@app.get("/api/scan/requests")
async def get_scan_requests(limit: int = 10):
    """
    v61.0: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –æ—á–µ—Ä–µ–¥—å –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ requests.json.
    """
    requests_list = _read_requests()

    return {
        "queue": requests_list[-limit:] if limit else requests_list,
        "count": len(requests_list)
    }


# v61.0: QUEUE SYNC —É–¥–∞–ª—ë–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º requests.json —Ñ–∞–π–ª


# ============================================================================
# v61.2: REAL-TIME CHANNEL SYNC
# ============================================================================

class ChannelSyncData(BaseModel):
    username: str
    status: str
    score: Optional[int] = None
    verdict: Optional[str] = None
    trust_factor: Optional[float] = None
    members: Optional[int] = None
    category: Optional[str] = None
    category_secondary: Optional[str] = None
    category_percent: Optional[int] = 100
    breakdown_json: Optional[str] = None
    title: Optional[str] = None
    description: Optional[str] = None


@app.post("/api/channels/sync")
async def sync_channel(data: ChannelSyncData):
    """
    v61.2: –û–±–Ω–æ–≤–∏—Ç—å –æ–¥–∏–Ω –∫–∞–Ω–∞–ª —á–µ—Ä–µ–∑ API (real-time sync).
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫—Ä–∞—É–ª–µ—Ä–æ–º –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ GOOD/BAD –∫–∞–Ω–∞–ª–∞.

    Upsert: –µ—Å–ª–∏ –∫–∞–Ω–∞–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –æ–±–Ω–æ–≤–ª—è–µ—Ç, –∏–Ω–∞—á–µ —Å–æ–∑–¥–∞—ë—Ç.
    """
    username = data.username.lower().lstrip('@')

    if not USERNAME_REGEX.match(username):
        return {"success": False, "error": "Invalid username format"}

    try:
        cursor = db.conn.cursor()
        cursor.execute("""
            INSERT INTO channels (
                username, status, score, verdict, trust_factor, members,
                category, category_secondary, category_percent,
                breakdown_json, title, description, scanned_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
            ON CONFLICT(username) DO UPDATE SET
                status = excluded.status,
                score = excluded.score,
                verdict = excluded.verdict,
                trust_factor = excluded.trust_factor,
                members = excluded.members,
                category = excluded.category,
                category_secondary = excluded.category_secondary,
                category_percent = excluded.category_percent,
                breakdown_json = excluded.breakdown_json,
                title = excluded.title,
                description = excluded.description,
                scanned_at = excluded.scanned_at
        """, (
            username,
            data.status,
            data.score,
            data.verdict,
            data.trust_factor,
            data.members,
            data.category,
            data.category_secondary,
            data.category_percent,
            data.breakdown_json,
            data.title,
            data.description
        ))
        db.conn.commit()
        return {"success": True, "username": username}
    except Exception as e:
        return {"success": False, "error": str(e)}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=3002)
