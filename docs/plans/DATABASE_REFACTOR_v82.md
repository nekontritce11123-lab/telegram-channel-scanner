# Database Refactoring Plan v82.0

**Generated by**: Swarm Mode (8 workers) + 4 Task Agents
**Date**: 2026-01-30

## Executive Summary

Refactoring `scanner/database.py` from 1484 lines to ~400 lines with:
- **Zero-migration schema** (adaptive JSON columns)
- **Simplified API** (50+ params → **kwargs)
- **Type safety** (Pydantic models)
- **Lazy loading** (split dataclasses)

---

## Current Problems

| Problem | Impact |
|---------|--------|
| 50+ columns in channels table | Hard to maintain |
| 12+ migration methods | 350 lines of boilerplate |
| 50+ params in mark_done/claim_and_complete | Unreadable signatures |
| ChannelRecord with 55 fields | Mixed concerns |
| Every new field = new migration | Slow iteration |

---

## Proposed Architecture

### 1. Adaptive Schema (Zero Migrations)

```sql
CREATE TABLE channels_v2 (
    -- Core indexed columns (16)
    username TEXT PRIMARY KEY,
    status TEXT DEFAULT 'WAITING',
    score INTEGER DEFAULT 0,
    verdict TEXT DEFAULT '',
    trust_factor REAL DEFAULT 1.0,
    members INTEGER DEFAULT 0,
    category TEXT,
    category_secondary TEXT,
    ad_status INTEGER,
    title TEXT,
    description TEXT,
    found_via TEXT DEFAULT '',
    priority INTEGER DEFAULT 0,
    raw_score INTEGER,
    scanned_at DATETIME,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    -- Adaptive JSON columns (5) - add fields without migrations!
    metrics_json TEXT,      -- cv_views, decay, reach, breakdown
    forensics_json TEXT,    -- penalties, conviction, bots, scam
    llm_json TEXT,          -- tier, ai_summary, brand_safety
    content_json TEXT,      -- posts, entities, media, ad_contacts
    raw_data_gz BLOB,       -- compressed messages/users for rescan

    -- Binary
    photo_blob BLOB
);
```

**Adding new field**: Just add to Pydantic model, no SQL migration needed!

### 2. Pydantic Models for JSON Columns

```python
class MetricsData(BaseModel):
    cv_views: Optional[float] = None
    decay_ratio: Optional[float] = None
    reach_percent: Optional[float] = None
    # ... add new fields freely

    class Config:
        extra = "allow"  # Accept unknown fields!

class ForensicsData(BaseModel):
    is_scam: bool = False
    bot_percentage: Optional[int] = None
    trust_penalties: list = []
    # ... add new fields freely
```

### 3. Simplified Update API

```python
# OLD (50+ params)
db.mark_done(
    username="test",
    status="GOOD",
    score=85,
    verdict="EXCELLENT",
    trust_factor=0.95,
    members=1000,
    # ... 45 more params
)

# NEW (**kwargs)
db.update_channel(
    "test",
    status="GOOD",
    score=85,
    metrics=MetricsData(cv_views=0.8, decay_ratio=0.92),
    forensics=ForensicsData(bot_percentage=5),
)

# Or pass dict from scanner
db.claim_and_complete("channel", **scan_result)
```

### 4. Split Dataclasses with Lazy Loading

```python
@dataclass
class ChannelCore:      # 10 fields - always loaded
    username, status, title, members, category...

@dataclass
class ChannelMetrics:   # 21 fields - on demand
    score, verdict, decay_ratio, avg_views...

@dataclass
class ChannelForensics: # 14 fields - on demand
    is_scam, bot_percentage, trust_penalties...

@dataclass
class ChannelRawData:   # 14 fields - heavy, lazy
    posts_text_gz, raw_messages_gz, photo_blob...
```

```python
# Fast list query (core only)
channels = db.get_channels_list(status='GOOD')
for ch in channels:
    print(ch.core.username, ch.metrics.score)

# Full detail (all data)
channel = db.get_channel_full("durov")
posts = channel.raw_data.get_posts_text()  # decompressed
```

---

## Migration Path

### Phase 1: Add New Code (non-breaking)
1. Add `CHANNELS_SCHEMA` dict
2. Add `_auto_migrate_columns()`
3. Add Pydantic models
4. Add `update_channel()` with **kwargs
5. Add split dataclasses

### Phase 2: Migrate Data
1. Create `channels_v2` table
2. Run `migrate_from_v1()`
3. Verify data integrity

### Phase 3: Switch Over
1. Point API to v2 methods
2. Deprecate old methods
3. Remove old migration code

### Phase 4: Cleanup
1. Drop channels_v1 table
2. Remove deprecated code
3. Update tests

---

## Benefits

| Metric | Before | After |
|--------|--------|-------|
| Lines of code | 1484 | ~400 |
| Migration methods | 12 | 0 |
| Columns | 50+ | 16 + 5 JSON |
| Method params | 50+ | **kwargs |
| Adding new field | 5 file changes | 1 line |
| Memory (list view) | 100% | ~40% |

---

## Files to Create/Modify

```
scanner/
├── database.py          # Simplified, ~400 lines
├── models/
│   ├── __init__.py
│   ├── channel.py       # ChannelCore/Metrics/Forensics/RawData
│   └── json_schemas.py  # Pydantic models for JSON columns
└── migrations/
    └── v1_to_v2.py      # One-time migration script
```

---

## Risk Mitigation

1. **Backward compat**: Keep old method signatures as wrappers
2. **Data safety**: Migrate to v2 table, keep v1 as backup
3. **Testing**: Full test coverage before switch
4. **Rollback**: v1 table preserved until v83.0

---

## Next Steps

1. [ ] Create `scanner/models/` directory
2. [ ] Implement Pydantic models
3. [ ] Add `_auto_migrate_columns()` to current database.py
4. [ ] Add `update_channel(**kwargs)` method
5. [ ] Create v1→v2 migration script
6. [ ] Test with staging database
7. [ ] Deploy to production
